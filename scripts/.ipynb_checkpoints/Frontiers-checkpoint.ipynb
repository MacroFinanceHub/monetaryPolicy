{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMB Model Frontiers based on a PI policy rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization file only\n",
    "\n",
    "If you are on the **monetaryPolicy** project, please use other file `PyLab.ipynb` for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell sets up the notebook to import numpy, seaborn, pandas, matplotlib etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook.\n",
    "\n",
    "# These lines import the Numpy, Pandas, Seaborn, Matplotlib modules.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing plotting libraries and styles\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# For Pandas to ignore FutureWarning displays\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `matlab.engine` using this link:\n",
    "\n",
    "https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell given below sets up MATLAB for the notebook\n",
    "Source: https://sehyoun.com/blog/20180904_using-matlab-with-jupyter-notebook.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "import io\n",
    "import scipy.io\n",
    "from IPython.core.magic import register_cell_magic\n",
    "ip = get_ipython()\n",
    "\n",
    "out = io.StringIO()\n",
    "err = io.StringIO()\n",
    "\n",
    "# Setup matlab cell magic #\n",
    "@register_cell_magic\n",
    "def matlab_magic(line,cell):\n",
    "    out.truncate(0)\n",
    "    out.seek(0)\n",
    "    err.truncate(0)\n",
    "    err.truncate(0)\n",
    "    raw = '''{line}.eval(\"\"\"{cell}\"\"\", nargout=0, stdout=out, stderr=err)'''\n",
    "    ip.run_cell(raw.format(line=line, cell=cell))\n",
    "    print(out.getvalue())\n",
    "    print(err.getvalue())\n",
    "    \n",
    "# Starting a MATLAB engine called eng\n",
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Change this to the file path on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the MMB.m as well as MMBOPT1.m and MMBOPT2.m folders to the MATLAB engine path\"\n",
    "eng.addpath(r'/Users/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2', nargout=0)\n",
    "eng.addpath(r'/Users/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2/MMB_OPTIONS', nargout=0)\n",
    "eng.addpath(r'/Users/Desktop/monetaryPolicy/scripts', nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important:\n",
    "The code below sets the coefficients and other data for the PID rule to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the coefficients table here:\n",
    "\n",
    "https://rishab231.github.io/img/coefficients.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets the coefficients of the monetary policy rule, there are 33 coefficients and len(coefficients) = 33\n",
    "coefficients = [0, 0, 0, 0, 1.5/4, 1.5/4, 1.5/4, 1.5/4, \n",
    "                0, 0, 0, 0, 0, 0.5, 0, 0, \n",
    "                0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                0, 0, 0, 0, 0, 0, 0, 1, 0.25]\n",
    "\n",
    "# Number of the model you want to chooose, please exclude 69-79, 19-22, 27, 59, 65, 68, 81, 97, 98\n",
    "modelNum = 1\n",
    "\n",
    "scipy.io.savemat('variables.mat', dict(coefficients=coefficients, modelNumber = modelNum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Important:** \n",
    "The cell below runs the MMB.m file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.MMB(nargout = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions defined to import data for:\n",
    "* 4 IRF: Impulse Response Function Variables (outputgap, inflation, interest, output) and `modelName`\n",
    "* All IRF Variables\n",
    "* 4 ACF: Autocorrelation Function Variables (outputgap, inflation, interest, output)\n",
    "* **Unconditional Variances**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelName():\n",
    "    irf_4 = pd.read_excel(\"../mmb-gui-mlab-2.3.2/OUTPUT/results.xls\", sheetname = \"IRF Mon. Pol. Shock      \")\n",
    "    irf_4 = irf_4.T\n",
    "    irf_headers = irf_4.iloc[0] # grab the first row for the header\n",
    "    irf_4 = irf_4[1:] # take the data less the header row\n",
    "    irf_4_stripped_headers = [myHeader.strip() for myHeader in np.array(irf_headers)] # removing trailing whitespaces\n",
    "    irf_4.columns = irf_4_stripped_headers\n",
    "    modelName = irf_4.columns.values[1]\n",
    "    return modelName\n",
    "\n",
    "def singleModel_irf4():\n",
    "    irf_4 = pd.read_excel(\"../mmb-gui-mlab-2.3.2/OUTPUT/results.xls\", sheetname = \"IRF Mon. Pol. Shock      \")\n",
    "    irf_4 = irf_4.T\n",
    "    irf_headers = irf_4.iloc[0] # grab the first row for the header\n",
    "    irf_4 = irf_4[1:] # take the data less the header row\n",
    "    irf_4_stripped_headers = [myHeader.strip() for myHeader in np.array(irf_headers)] # removing trailing whitespaces\n",
    "    irf_4.columns = irf_4_stripped_headers\n",
    "    modelName = irf_4.columns.values[1]\n",
    "    irf_4 = irf_4.iloc[:, [i for i in range(1, len(irf_4.columns.values), 2)]]\n",
    "    irf_4.columns = [\"OutputGap\", \"Inflation\", \"Interest\", \"Output\"]\n",
    "    irf_4 = irf_4.reset_index()\n",
    "    irf_4.index.name = \"Period\"\n",
    "    irf_4.drop('index', axis=1, inplace=True)\n",
    "    return irf_4\n",
    "\n",
    "def singleModel_allirf():\n",
    "    old_irf_df = pd.read_excel(\"../mmb-gui-mlab-2.3.2/OUTPUT/results.xls\", sheetname = \"all IRFs Mon. Pol. Shock\")\n",
    "    all_irf = old_irf_df.T\n",
    "    new_header = all_irf.iloc[0] # grab the first row for the header\n",
    "    all_irf = all_irf[1:] # take the data less the header row\n",
    "    stripped_headers = [myHeader.strip() for myHeader in np.array(new_header)] # removing trailing whitespaces\n",
    "    all_irf.columns = stripped_headers # set the header row as the df header\n",
    "    all_irf[\"c_t\"] = all_irf.index\n",
    "    all_irf.index = np.arange(0,21,1)\n",
    "    all_irf.index.name = \"Period\"\n",
    "\n",
    "    # This section rearranges the columns\n",
    "    n = len(list(all_irf.columns.values))\n",
    "    rearranged = [list(all_irf.columns.values)[-1]] + list(all_irf.columns.values)[:n-1]\n",
    "    all_irf = all_irf[rearranged]\n",
    "    return all_irf\n",
    "\n",
    "def singleModel_acf():\n",
    "    acf = pd.read_excel(\"../mmb-gui-mlab-2.3.2/OUTPUT/results.xls\", sheetname = \"ACF\")\n",
    "    acf = acf.T\n",
    "    acf_headers = acf.iloc[0] # grab the first row for the header\n",
    "    acf = acf[1:] # take the data less the header row\n",
    "    acf_stripped_headers = [myHeader.strip() for myHeader in np.array(acf_headers)] # removing trailing whitespaces\n",
    "    acf.columns = acf_stripped_headers\n",
    "    acf = acf.iloc[:, [i for i in range(0, len(acf.columns.values), 2)]]\n",
    "    acf.columns = [\"OutputGap\", \"Inflation\", \"Interest\", \"Output\"]\n",
    "    acf = acf.reset_index()\n",
    "    acf.index.name = \"Period\"\n",
    "    acf.drop('index', axis=1, inplace=True)\n",
    "    return acf\n",
    "\n",
    "def unconditionalVariances():\n",
    "    var4 = pd.read_csv(\"../mmb-gui-mlab-2.3.2/OUTPUT/variances.csv\", names=[\"interest\", \"inflation\", \"outputgap\", \"output\"])\n",
    "    return var4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutputGap</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Interest</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.823109</td>\n",
       "      <td>-0.0181086</td>\n",
       "      <td>0.561283</td>\n",
       "      <td>-0.823109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0414876</td>\n",
       "      <td>-0.0161234</td>\n",
       "      <td>-0.00344134</td>\n",
       "      <td>0.0414876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OutputGap  Inflation    Interest     Output\n",
       "Period                                             \n",
       "0               0          0           0          0\n",
       "1       -0.823109 -0.0181086    0.561283  -0.823109\n",
       "2       0.0414876 -0.0161234 -0.00344134  0.0414876"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleModel_irf4().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutputGap</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Interest</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661577</td>\n",
       "      <td>0.716781</td>\n",
       "      <td>0.755958</td>\n",
       "      <td>0.730718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375576</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>0.590853</td>\n",
       "      <td>0.520949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OutputGap Inflation  Interest    Output\n",
       "Period                                        \n",
       "0              1         1         1         1\n",
       "1       0.661577  0.716781  0.755958  0.730718\n",
       "2       0.375576  0.478675  0.590853  0.520949"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleModel_acf().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Calculating `unconditionalVariances` for different models, in an array of `modelNums`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myVariance(modelNums, coeff):\n",
    "    variances = dict()\n",
    "    for modelNum in modelNums:\n",
    "        eng.MMB(nargout = 0)\n",
    "        scipy.io.savemat('variables.mat', dict(coefficients=coeff, modelNumber = modelNum))\n",
    "        modelName = getModelName()\n",
    "        variances[modelName] = unconditionalVariances().values.tolist()[0]\n",
    "    return variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating unconditional variances for different rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NK_RW97': [0.079687, 0.06191, 0.38900999999999997, 1.1702]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myVariance([1], coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hawkins PI Optimization (Williams Paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`selected_coeff` has $\\beta^{(\\pi_t)}, \\beta^{(\\pi_{t-1})}, \\beta^{(y_t)}, \\beta^{(y_{t-1})}$ \n",
    "\n",
    "So, the policy rule becomes:\n",
    "\n",
    "$r_t = r_{t-1} + \\beta^{(\\pi_t)}\\pi_t + \\beta^{(\\pi_{t-1})}\\pi_{t-1} + \\beta^{(y_t)}y_t + \\beta^{(y_{t-1})}y_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_final_inflation_variance = 0\n",
    "PID_final_output_gap_variance = 0\n",
    "PID_final_interest_variance = 0\n",
    "currentPIDLoss = 0\n",
    "\n",
    "def myPID(selected_coeff, lambdaVal, coeffInterest, modelNum, rVarTarget):\n",
    "    global PID_final_inflation_variance\n",
    "    global PID_final_output_gap_variance\n",
    "    global PID_final_interest_variance\n",
    "    global currentPIDLoss\n",
    "\n",
    "    coefficients = [1, 0, 0, 0, \n",
    "                    abs(selected_coeff[0])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    selected_coeff[1]/4, \n",
    "                    0, 0, 0, 0, \n",
    "                    selected_coeff[2], selected_coeff[3], 0, \n",
    "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.25]    \n",
    "    scipy.io.savemat('variables.mat', dict(coefficients=coefficients, modelNumber = modelNum)) # Input for MMB.\n",
    "    eng.MMB(nargout = 0)\n",
    "    \n",
    "    interest_rate_variance = unconditionalVariances()['interest'][0]\n",
    "    inflation_variance = unconditionalVariances()['inflation'][0]\n",
    "    output_gap_variance = unconditionalVariances()['outputgap'][0]\n",
    "    \n",
    "    PID_final_inflation_variance = inflation_variance\n",
    "    PID_final_output_gap_variance = output_gap_variance\n",
    "    PID_final_interest_variance = interest_rate_variance\n",
    "    \n",
    "    PID_loss = ((interest_rate_variance - rVarTarget)**2 * coeffInterest \n",
    "                + inflation_variance * lambdaVal\n",
    "                + output_gap_variance * (1 - lambdaVal))\n",
    "    \n",
    "    currentPIDLoss = PID_loss\n",
    "    print(\"lambda =\", lambdaVal, \"current_loss =\", currentPIDLoss)\n",
    "    \n",
    "    return PID_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFrontier(modelNum):\n",
    "    rVarTarget = 16.0 # Target rate variance from Williams paper.\n",
    "    taylor_coeff = [1.5, 0, 0.5, 0] # Taylor rule coefficients.\n",
    "    hamilton_coeff = [1.42, -1.20, 0.5, -0.48] # Hamilton fit coefficients.\n",
    "    weights = np.arange(0, 1.01, .25) # Values for lambda\n",
    "    interest_coeff = 1.0 # Coefficient on the interest_rate loss term\n",
    "    \n",
    "    mylambdatemp = 0.0 # Something to put in the lambda variable when calculating the target rate variance.\n",
    "    # Run with Hamilton coefficients to generate target rate variance.\n",
    "    myfoo = myPID(hamilton_coeff, mylambdatemp, interest_coeff, modelNum, rVarTarget)\n",
    "    rVarTarget = unconditionalVariances()['interest'][0] # Assign target rate variance.\n",
    "    print(\"The target rate variance is\", rVarTarget) # Print assigned rate variance.\n",
    "    \n",
    "    PID_inflation_variances = []\n",
    "    PID_output_gap_variances = []\n",
    "    PID_interest_variances = []\n",
    "    PID_loss_of_lambda = []\n",
    "    PID_coefficients_array = []\n",
    "\n",
    "    # Starting with the Taylor rule coefficients\n",
    "    #current_coeff = taylor_coeff\n",
    "    \n",
    "    # Starting with the Hamilton rule coefficients\n",
    "    current_coeff = hamilton_coeff\n",
    "\n",
    "    for lambda_value in weights:\n",
    "        PID_result = scipy.optimize.minimize(myPID, current_coeff, \\\n",
    "                                    args=(lambda_value, interest_coeff, modelNum, rVarTarget), method='Nelder-Mead')\n",
    "        current_coeff = PID_result.x\n",
    "        PID_coefficients_array.append(current_coeff)\n",
    "        PID_inflation_variances.append(PID_final_inflation_variance)\n",
    "        PID_output_gap_variances.append(PID_final_output_gap_variance)\n",
    "        PID_interest_variances.append(PID_final_interest_variance)\n",
    "        PID_loss_of_lambda.append(currentPIDLoss)\n",
    "    \n",
    "    # The code below plots the frontier\n",
    "    nameOfModel = getModelName()\n",
    "    \n",
    "    SD_inflation_scatter = np.sqrt(np.asarray(PID_inflation_variances))\n",
    "    SD_output_gap_scatter = np.sqrt(np.asarray(PID_output_gap_variances))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(SD_inflation_scatter, SD_output_gap_scatter, color=\"red\")\n",
    "\n",
    "    for i in range(0, len(weights)):\n",
    "        ax.annotate(weights[i], (SD_inflation_scatter[i], SD_output_gap_scatter[i]))\n",
    "\n",
    "    ax.set_xlabel('$\\sigma_{\\pi}$', fontsize=10)\n",
    "    ax.set_ylabel('$\\sigma_{y}$', fontsize=10)\n",
    "    ax.set_title('Policy Frontiers for Different Weights, Model: ' + nameOfModel, fontsize=14)\n",
    "    \n",
    "    # The code below saves the results of the all the optimizations with the appropriate lambdas into a DataFrame\n",
    "    results = dict()\n",
    "    results['lambdas'] = weights\n",
    "    results['inflation_variance'] = PID_inflation_variances\n",
    "    results['output_gap_variance'] = PID_output_gap_variances\n",
    "    results['interest_variance'] = PID_interest_variances\n",
    "    results['loss'] = PID_loss_of_lambda\n",
    "    results['coefficients'] = PID_coefficients_array\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    \n",
    "    # Saving DataFrame to nameOfModel.csv file\n",
    "    results_df.to_csv(nameOfModel + \".csv\", index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.0 current_loss = 95.195944\n",
      "The target rate variance is 22.712\n",
      "lambda = 0.0 current_loss = 50.145\n",
      "lambda = 0.0 current_loss = 49.301324\n",
      "lambda = 0.0 current_loss = 83.28424400000003\n",
      "lambda = 0.0 current_loss = 41.978401\n",
      "lambda = 0.0 current_loss = 98.97032400000003\n",
      "lambda = 0.0 current_loss = 43.530401\n",
      "lambda = 0.0 current_loss = 39.797743999999994\n",
      "lambda = 0.0 current_loss = 32.041241\n",
      "lambda = 0.0 current_loss = 32.382321000000005\n",
      "lambda = 0.0 current_loss = 32.86604899999999\n",
      "lambda = 0.0 current_loss = 28.312943999999998\n",
      "lambda = 0.0 current_loss = 43.439944\n",
      "lambda = 0.0 current_loss = 44.444049000000014\n",
      "lambda = 0.0 current_loss = 39.997009\n",
      "lambda = 0.0 current_loss = 28.859889000000006\n",
      "lambda = 0.0 current_loss = 43.94340900000001\n",
      "lambda = 0.0 current_loss = 28.986881000000004\n",
      "lambda = 0.0 current_loss = 30.41559999999999\n",
      "lambda = 0.0 current_loss = 26.4956\n",
      "lambda = 0.0 current_loss = 30.891728999999994\n",
      "lambda = 0.0 current_loss = 26.072644\n",
      "lambda = 0.0 current_loss = 29.033209\n",
      "lambda = 0.0 current_loss = 34.26722399999999\n",
      "lambda = 0.0 current_loss = 26.333225000000002\n",
      "lambda = 0.0 current_loss = 25.944035999999993\n",
      "lambda = 0.0 current_loss = 28.981904\n",
      "lambda = 0.0 current_loss = 22.989796\n",
      "lambda = 0.0 current_loss = 21.727800999999992\n",
      "lambda = 0.0 current_loss = 33.872356\n",
      "lambda = 0.0 current_loss = 23.760024999999995\n",
      "lambda = 0.0 current_loss = 21.982641000000005\n",
      "lambda = 0.0 current_loss = 20.248444\n",
      "lambda = 0.0 current_loss = 18.195049\n",
      "lambda = 0.0 current_loss = 18.183249000000004\n",
      "lambda = 0.0 current_loss = 19.864529\n",
      "lambda = 0.0 current_loss = 16.587636\n",
      "lambda = 0.0 current_loss = 38.52868900000001\n",
      "lambda = 0.0 current_loss = 16.808884\n",
      "lambda = 0.0 current_loss = 19.84309999999999\n",
      "lambda = 0.0 current_loss = 17.209163999999998\n",
      "lambda = 0.0 current_loss = 18.37351599999999\n",
      "lambda = 0.0 current_loss = 17.347849\n",
      "lambda = 0.0 current_loss = 17.87544900000001\n",
      "lambda = 0.0 current_loss = 16.574641000000003\n",
      "lambda = 0.0 current_loss = 19.101\n",
      "lambda = 0.0 current_loss = 16.804236\n",
      "lambda = 0.0 current_loss = 16.628024\n",
      "lambda = 0.0 current_loss = 16.796761\n",
      "lambda = 0.0 current_loss = 16.950920999999997\n",
      "lambda = 0.0 current_loss = 16.600008999999996\n",
      "lambda = 0.0 current_loss = 16.660399999999996\n",
      "lambda = 0.0 current_loss = 16.487481000000002\n",
      "lambda = 0.0 current_loss = 16.749921000000004\n",
      "lambda = 0.0 current_loss = 16.496121\n",
      "lambda = 0.0 current_loss = 16.511024999999997\n",
      "lambda = 0.0 current_loss = 16.680015999999995\n",
      "lambda = 0.0 current_loss = 16.466321\n",
      "lambda = 0.0 current_loss = 16.6604\n",
      "lambda = 0.0 current_loss = 16.460561\n",
      "lambda = 0.0 current_loss = 16.594564\n",
      "lambda = 0.0 current_loss = 16.441281\n",
      "lambda = 0.0 current_loss = 16.609880999999998\n",
      "lambda = 0.0 current_loss = 16.443881\n",
      "lambda = 0.0 current_loss = 16.4391\n",
      "lambda = 0.0 current_loss = 16.515624999999996\n",
      "lambda = 0.0 current_loss = 16.443856\n",
      "lambda = 0.0 current_loss = 16.4334\n",
      "lambda = 0.0 current_loss = 16.484856000000004\n",
      "lambda = 0.0 current_loss = 16.534515999999996\n",
      "lambda = 0.0 current_loss = 16.422296\n",
      "lambda = 0.0 current_loss = 16.493636\n",
      "lambda = 0.0 current_loss = 16.423744\n",
      "lambda = 0.0 current_loss = 16.433215999999998\n",
      "lambda = 0.0 current_loss = 16.410040999999996\n",
      "lambda = 0.0 current_loss = 16.408404\n",
      "lambda = 0.0 current_loss = 16.403063999999997\n",
      "lambda = 0.0 current_loss = 16.410224999999993\n",
      "lambda = 0.0 current_loss = 16.446321\n",
      "lambda = 0.0 current_loss = 16.413481000000004\n",
      "lambda = 0.0 current_loss = 16.438684000000002\n",
      "lambda = 0.0 current_loss = 16.410360999999998\n",
      "lambda = 0.0 current_loss = 16.385296\n",
      "lambda = 0.0 current_loss = 16.367296\n",
      "lambda = 0.0 current_loss = 16.388169\n",
      "lambda = 0.0 current_loss = 16.378184\n",
      "lambda = 0.0 current_loss = 16.368025\n",
      "lambda = 0.0 current_loss = 16.3409\n",
      "lambda = 0.0 current_loss = 16.314116000000002\n",
      "lambda = 0.0 current_loss = 16.319356000000003\n",
      "lambda = 0.0 current_loss = 16.310783999999998\n",
      "lambda = 0.0 current_loss = 16.295224999999995\n",
      "lambda = 0.0 current_loss = 16.277281\n",
      "lambda = 0.0 current_loss = 16.252281\n",
      "lambda = 0.0 current_loss = 16.202096000000004\n",
      "lambda = 0.0 current_loss = 16.123624999999997\n",
      "lambda = 0.0 current_loss = 16.151443999999998\n",
      "lambda = 0.0 current_loss = 16.107440999999998\n",
      "lambda = 0.0 current_loss = 16.061849\n",
      "lambda = 0.0 current_loss = 16.008441\n",
      "lambda = 0.0 current_loss = 15.940160999999998\n",
      "lambda = 0.0 current_loss = 15.833224999999999\n",
      "lambda = 0.0 current_loss = 15.660841000000003\n",
      "lambda = 0.0 current_loss = 15.692344000000002\n",
      "lambda = 0.0 current_loss = 15.611899999999999\n",
      "lambda = 0.0 current_loss = 15.668864\n",
      "lambda = 0.0 current_loss = 15.434880999999999\n",
      "lambda = 0.0 current_loss = 15.263624\n",
      "lambda = 0.0 current_loss = 15.213196000000002\n",
      "lambda = 0.0 current_loss = 15.1931\n",
      "lambda = 0.0 current_loss = 14.981728999999998\n",
      "lambda = 0.0 current_loss = 14.826964000000002\n",
      "lambda = 0.0 current_loss = 14.755603999999998\n",
      "lambda = 0.0 current_loss = 15.171409000000002\n",
      "lambda = 0.0 current_loss = 14.415921000000003\n",
      "lambda = 0.0 current_loss = 14.560224999999994\n",
      "lambda = 0.0 current_loss = 17.340489\n",
      "lambda = 0.0 current_loss = 14.818440999999998\n",
      "lambda = 0.0 current_loss = 14.264961000000001\n",
      "lambda = 0.0 current_loss = 14.018995999999998\n",
      "lambda = 0.0 current_loss = 14.162399999999998\n",
      "lambda = 0.0 current_loss = 14.106523999999999\n",
      "lambda = 0.0 current_loss = 13.663099999999996\n",
      "lambda = 0.0 current_loss = 13.555321\n",
      "lambda = 0.0 current_loss = 13.450769\n",
      "lambda = 0.0 current_loss = 13.209129\n",
      "lambda = 0.0 current_loss = 13.711201\n",
      "lambda = 0.0 current_loss = 13.211249000000002\n",
      "lambda = 0.0 current_loss = 16.36800400000001\n",
      "lambda = 0.0 current_loss = 13.519736\n",
      "lambda = 0.0 current_loss = 13.613696000000001\n",
      "lambda = 0.0 current_loss = 13.378081\n",
      "lambda = 0.0 current_loss = 13.519044\n",
      "lambda = 0.0 current_loss = 13.035481\n",
      "lambda = 0.0 current_loss = 13.177688999999999\n",
      "lambda = 0.0 current_loss = 13.360556\n",
      "lambda = 0.0 current_loss = 13.484625000000001\n",
      "lambda = 0.0 current_loss = 13.215956\n",
      "lambda = 0.0 current_loss = 13.370529\n",
      "lambda = 0.0 current_loss = 13.185084\n",
      "lambda = 0.0 current_loss = 13.113704\n",
      "lambda = 0.0 current_loss = 13.0549\n",
      "lambda = 0.0 current_loss = 13.234281\n",
      "lambda = 0.0 current_loss = 13.118929000000001\n",
      "lambda = 0.0 current_loss = 13.014625\n",
      "lambda = 0.0 current_loss = 13.009064\n",
      "lambda = 0.0 current_loss = 12.958599999999997\n",
      "lambda = 0.0 current_loss = 13.014960999999998\n",
      "lambda = 0.0 current_loss = 13.087761\n",
      "lambda = 0.0 current_loss = 13.020849\n",
      "lambda = 0.0 current_loss = 12.942316\n",
      "lambda = 0.0 current_loss = 12.978921\n",
      "lambda = 0.0 current_loss = 12.9436\n",
      "lambda = 0.0 current_loss = 12.958583999999998\n",
      "lambda = 0.0 current_loss = 13.057441\n",
      "lambda = 0.0 current_loss = 12.957399999999998\n",
      "lambda = 0.0 current_loss = 12.950104\n",
      "lambda = 0.0 current_loss = 13.020404\n",
      "lambda = 0.0 current_loss = 12.936656000000001\n",
      "lambda = 0.0 current_loss = 12.956089\n",
      "lambda = 0.0 current_loss = 12.937849\n",
      "lambda = 0.0 current_loss = 12.937824\n",
      "lambda = 0.0 current_loss = 12.966616000000004\n",
      "lambda = 0.0 current_loss = 12.934244\n",
      "lambda = 0.0 current_loss = 12.966344000000003\n",
      "lambda = 0.0 current_loss = 12.933244\n",
      "lambda = 0.0 current_loss = 12.945523999999999\n",
      "lambda = 0.0 current_loss = 12.932099999999998\n",
      "lambda = 0.0 current_loss = 12.944560999999998\n",
      "lambda = 0.0 current_loss = 12.932401000000002\n",
      "lambda = 0.0 current_loss = 12.931044000000002\n",
      "lambda = 0.0 current_loss = 12.933816\n",
      "lambda = 0.0 current_loss = 12.936204\n",
      "lambda = 0.0 current_loss = 12.931895999999998\n",
      "lambda = 0.0 current_loss = 12.929969\n",
      "lambda = 0.0 current_loss = 12.933521000000002\n",
      "lambda = 0.0 current_loss = 12.933316000000001\n",
      "lambda = 0.0 current_loss = 12.930489\n",
      "lambda = 0.0 current_loss = 12.930201\n",
      "lambda = 0.0 current_loss = 12.927569\n",
      "lambda = 0.0 current_loss = 12.926556000000001\n",
      "lambda = 0.0 current_loss = 12.928804000000001\n",
      "lambda = 0.0 current_loss = 12.925225\n",
      "lambda = 0.0 current_loss = 12.923336\n",
      "lambda = 0.0 current_loss = 12.925024999999998\n",
      "lambda = 0.0 current_loss = 12.922489\n",
      "lambda = 0.0 current_loss = 12.923635999999998\n",
      "lambda = 0.0 current_loss = 12.9195\n",
      "lambda = 0.0 current_loss = 12.917641\n",
      "lambda = 0.0 current_loss = 12.915224\n",
      "lambda = 0.0 current_loss = 12.911624999999997\n",
      "lambda = 0.0 current_loss = 12.917376\n",
      "lambda = 0.0 current_loss = 12.909904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.0 current_loss = 12.906025\n",
      "lambda = 0.0 current_loss = 12.903801\n",
      "lambda = 0.0 current_loss = 12.899844\n",
      "lambda = 0.0 current_loss = 12.896641\n",
      "lambda = 0.0 current_loss = 12.891903999999998\n",
      "lambda = 0.0 current_loss = 12.880161000000001\n",
      "lambda = 0.0 current_loss = 12.865025000000001\n",
      "lambda = 0.0 current_loss = 12.878876\n",
      "lambda = 0.0 current_loss = 12.869769000000002\n",
      "lambda = 0.0 current_loss = 12.877756\n",
      "lambda = 0.0 current_loss = 12.847716000000002\n",
      "lambda = 0.0 current_loss = 12.835124\n",
      "lambda = 0.0 current_loss = 12.870049000000002\n",
      "lambda = 0.0 current_loss = 12.835724\n",
      "lambda = 0.0 current_loss = 12.868401\n",
      "lambda = 0.0 current_loss = 12.820744\n",
      "lambda = 0.0 current_loss = 12.798395999999999\n",
      "lambda = 0.0 current_loss = 12.812615999999998\n",
      "lambda = 0.0 current_loss = 12.779281000000001\n",
      "lambda = 0.0 current_loss = 12.775504000000002\n",
      "lambda = 0.0 current_loss = 12.789796\n",
      "lambda = 0.0 current_loss = 12.7136\n",
      "lambda = 0.0 current_loss = 12.658025\n",
      "the MATLAB function has been cancelled\n",
      "lambda = 0.0 current_loss = 12.658025\n"
     ]
    },
    {
     "ename": "MatlabExecutionError",
     "evalue": "\n  File /Users/rishabsrivastava/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2/MMB.m, line 15, in MMB\n'../scripts/variables.mat' is not found in the current folder or on the MATLAB path, but exists in:\n    /Users/rishabsrivastava/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2\n\nChange the MATLAB current folder or add its folder to the MATLAB path.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMatlabExecutionError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0923693ef784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm15results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateFrontier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-4abd3863b7e5>\u001b[0m in \u001b[0;36mcreateFrontier\u001b[0;34m(modelNum)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlambda_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         PID_result = scipy.optimize.minimize(myPID, current_coeff, \\\n\u001b[0;32m---> 28\u001b[0;31m                                     args=(lambda_value, interest_coeff, modelNum, rVarTarget), method='Nelder-Mead')\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mcurrent_coeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPID_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mPID_coefficients_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_coeff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    473\u001b[0m                       callback=callback, **options)\n\u001b[1;32m    474\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, **unknown_options)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b6312405e96f>\u001b[0m in \u001b[0;36mmyPID\u001b[0;34m(selected_coeff, lambdaVal, coeffInterest, modelNum, rVarTarget)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.25]    \n\u001b[1;32m     21\u001b[0m     \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavemat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variables.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelNumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Input for MMB.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0meng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMMB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnargout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0minterest_rate_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconditionalVariances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matlab/engine/matlabengine.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             return FutureResult(self._engine(), future, nargs, _stdout,\n\u001b[0;32m---> 71\u001b[0;31m                                 _stderr, feval=True).result()\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__validate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matlab/engine/futureresult.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpythonengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TimeoutCannotBeNegative'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matlab/engine/fevalfuture.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpythonengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MatlabFunctionTimeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpythonengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFEvalResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nargout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMatlabExecutionError\u001b[0m: \n  File /Users/rishabsrivastava/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2/MMB.m, line 15, in MMB\n'../scripts/variables.mat' is not found in the current folder or on the MATLAB path, but exists in:\n    /Users/rishabsrivastava/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2\n\nChange the MATLAB current folder or add its folder to the MATLAB path.\n"
     ]
    }
   ],
   "source": [
    "m15results = createFrontier(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambdas</th>\n",
       "      <th>inflation_variance</th>\n",
       "      <th>output_gap_variance</th>\n",
       "      <th>interest_variance</th>\n",
       "      <th>losses</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>32.2720</td>\n",
       "      <td>13.906</td>\n",
       "      <td>16.170</td>\n",
       "      <td>13.934900</td>\n",
       "      <td>[-0.22051918628999112, 0.0013264097158561397, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125</td>\n",
       "      <td>22.6760</td>\n",
       "      <td>14.458</td>\n",
       "      <td>16.188</td>\n",
       "      <td>15.520594</td>\n",
       "      <td>[-0.2700526295155092, 0.0013308918150854623, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250</td>\n",
       "      <td>18.0110</td>\n",
       "      <td>15.485</td>\n",
       "      <td>16.224</td>\n",
       "      <td>16.166676</td>\n",
       "      <td>[-0.30571205625143016, 0.0011227951134167862, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375</td>\n",
       "      <td>14.9090</td>\n",
       "      <td>16.866</td>\n",
       "      <td>16.248</td>\n",
       "      <td>16.193629</td>\n",
       "      <td>[-0.3368461663245146, 0.0011298881515955676, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>12.5520</td>\n",
       "      <td>18.685</td>\n",
       "      <td>16.257</td>\n",
       "      <td>15.684549</td>\n",
       "      <td>[-0.36634825765828977, 0.0011447401706699016, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625</td>\n",
       "      <td>10.4090</td>\n",
       "      <td>21.441</td>\n",
       "      <td>16.259</td>\n",
       "      <td>14.613081</td>\n",
       "      <td>[-0.3994760140949899, 0.0011044817808612858, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.750</td>\n",
       "      <td>8.2562</td>\n",
       "      <td>26.321</td>\n",
       "      <td>16.241</td>\n",
       "      <td>12.830481</td>\n",
       "      <td>[-0.4418438174574822, 0.0010697404039113796, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.875</td>\n",
       "      <td>5.9515</td>\n",
       "      <td>37.099</td>\n",
       "      <td>16.193</td>\n",
       "      <td>9.882186</td>\n",
       "      <td>[-0.5054289602149964, 0.0010652964560608578, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3.4858</td>\n",
       "      <td>88.649</td>\n",
       "      <td>16.069</td>\n",
       "      <td>3.490561</td>\n",
       "      <td>[-0.6681029822357823, 0.0014506820306309294, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambdas  inflation_variance  output_gap_variance  interest_variance  \\\n",
       "0    0.000             32.2720               13.906             16.170   \n",
       "1    0.125             22.6760               14.458             16.188   \n",
       "2    0.250             18.0110               15.485             16.224   \n",
       "3    0.375             14.9090               16.866             16.248   \n",
       "4    0.500             12.5520               18.685             16.257   \n",
       "5    0.625             10.4090               21.441             16.259   \n",
       "6    0.750              8.2562               26.321             16.241   \n",
       "7    0.875              5.9515               37.099             16.193   \n",
       "8    1.000              3.4858               88.649             16.069   \n",
       "\n",
       "      losses                                       coefficients  \n",
       "0  13.934900  [-0.22051918628999112, 0.0013264097158561397, ...  \n",
       "1  15.520594  [-0.2700526295155092, 0.0013308918150854623, 0...  \n",
       "2  16.166676  [-0.30571205625143016, 0.0011227951134167862, ...  \n",
       "3  16.193629  [-0.3368461663245146, 0.0011298881515955676, 0...  \n",
       "4  15.684549  [-0.36634825765828977, 0.0011447401706699016, ...  \n",
       "5  14.613081  [-0.3994760140949899, 0.0011044817808612858, 0...  \n",
       "6  12.830481  [-0.4418438174574822, 0.0010697404039113796, 0...  \n",
       "7   9.882186  [-0.5054289602149964, 0.0010652964560608578, 0...  \n",
       "8   3.490561  [-0.6681029822357823, 0.0014506820306309294, 3...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m15results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of EuroArea Model Frontiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Est_EA_Models = [34, 35, 36, 37, 38, 39, 40, 41, 57, 68, 82, 94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 80.70782100000001 lambda= 0.0\n",
      "Total PID Loss 111.41104400000002 lambda= 0.0\n",
      "Total PID Loss 80.77844900000002 lambda= 0.0\n",
      "Total PID Loss 81.30432399999994 lambda= 0.0\n",
      "Total PID Loss 80.741581 lambda= 0.0\n",
      "Total PID Loss 56.29202899999995 lambda= 0.0\n",
      "Total PID Loss 37.10202400000001 lambda= 0.0\n",
      "Total PID Loss 55.57552499999999 lambda= 0.0\n",
      "Total PID Loss 45.63219999999999 lambda= 0.0\n",
      "Total PID Loss 32.56613599999998 lambda= 0.0\n",
      "Total PID Loss 17.920429000000006 lambda= 0.0\n",
      "Total PID Loss 12.668341000000005 lambda= 0.0\n",
      "Total PID Loss 3.4428240000000003 lambda= 0.0\n",
      "Total PID Loss 4.798821000000004 lambda= 0.0\n",
      "Total PID Loss 3.067589 lambda= 0.0\n",
      "Total PID Loss 11.503389000000007 lambda= 0.0\n",
      "Total PID Loss 9.010741000000008 lambda= 0.0\n",
      "Total PID Loss 14.937300999999989 lambda= 0.0\n",
      "Total PID Loss 6.905361000000004 lambda= 0.0\n",
      "Total PID Loss 9.04020900000001 lambda= 0.0\n",
      "Total PID Loss 4.7768690000000005 lambda= 0.0\n",
      "Total PID Loss 8.676200999999992 lambda= 0.0\n",
      "Total PID Loss 3.987843999999998 lambda= 0.0\n",
      "Total PID Loss 8.281889000000003 lambda= 0.0\n",
      "Total PID Loss 3.1230239999999987 lambda= 0.0\n",
      "Total PID Loss 4.458900000000002 lambda= 0.0\n",
      "Total PID Loss 3.283899999999999 lambda= 0.0\n",
      "Total PID Loss 5.941356000000001 lambda= 0.0\n",
      "Total PID Loss 3.1181040000000007 lambda= 0.0\n",
      "Total PID Loss 3.090299999999999 lambda= 0.0\n",
      "Total PID Loss 3.719061 lambda= 0.0\n",
      "Total PID Loss 2.992581 lambda= 0.0\n",
      "Total PID Loss 3.6813009999999977 lambda= 0.0\n",
      "Total PID Loss 2.959521 lambda= 0.0\n",
      "Total PID Loss 2.899104 lambda= 0.0\n",
      "Total PID Loss 2.942083999999999 lambda= 0.0\n",
      "Total PID Loss 3.2337039999999995 lambda= 0.0\n",
      "Total PID Loss 2.9653559999999994 lambda= 0.0\n",
      "Total PID Loss 3.0507039999999996 lambda= 0.0\n",
      "Total PID Loss 2.9575 lambda= 0.0\n",
      "Total PID Loss 2.8867 lambda= 0.0\n",
      "Total PID Loss 2.891576000000001 lambda= 0.0\n",
      "Total PID Loss 3.0386000000000006 lambda= 0.0\n",
      "Total PID Loss 2.917561 lambda= 0.0\n",
      "Total PID Loss 2.844436 lambda= 0.0\n",
      "Total PID Loss 2.7936159999999997 lambda= 0.0\n",
      "Total PID Loss 2.895869 lambda= 0.0\n",
      "Total PID Loss 2.785929 lambda= 0.0\n",
      "Total PID Loss 2.7206760000000005 lambda= 0.0\n",
      "Total PID Loss 2.8214 lambda= 0.0\n",
      "Total PID Loss 2.7249999999999996 lambda= 0.0\n",
      "Total PID Loss 2.6167890000000003 lambda= 0.0\n",
      "Total PID Loss 2.4861009999999997 lambda= 0.0\n",
      "Total PID Loss 2.6636210000000005 lambda= 0.0\n",
      "Total PID Loss 2.488509 lambda= 0.0\n",
      "Total PID Loss 2.4347010000000004 lambda= 0.0\n",
      "Total PID Loss 2.310569 lambda= 0.0\n",
      "Total PID Loss 2.295784 lambda= 0.0\n",
      "Total PID Loss 2.2370010000000002 lambda= 0.0\n",
      "Total PID Loss 2.073929 lambda= 0.0\n",
      "Total PID Loss 1.9318759999999997 lambda= 0.0\n",
      "Total PID Loss 2.011429000000001 lambda= 0.0\n",
      "Total PID Loss 2.5155240000000028 lambda= 0.0\n",
      "Total PID Loss 2.222096 lambda= 0.0\n",
      "Total PID Loss 2.0963999999999983 lambda= 0.0\n",
      "Total PID Loss 1.8308 lambda= 0.0\n",
      "Total PID Loss 1.7612640000000004 lambda= 0.0\n",
      "Total PID Loss 3.016460999999995 lambda= 0.0\n",
      "Total PID Loss 1.9907360000000003 lambda= 0.0\n",
      "Total PID Loss 1.9004089999999998 lambda= 0.0\n",
      "Total PID Loss 1.764764 lambda= 0.0\n",
      "Total PID Loss 1.6767009999999987 lambda= 0.0\n",
      "Total PID Loss 1.7882359999999973 lambda= 0.0\n",
      "Total PID Loss 1.597025 lambda= 0.0\n",
      "Total PID Loss 1.493781 lambda= 0.0\n",
      "Total PID Loss 1.8558640000000017 lambda= 0.0\n",
      "Total PID Loss 1.6295809999999984 lambda= 0.0\n",
      "Total PID Loss 1.942923999999999 lambda= 0.0\n",
      "Total PID Loss 1.6572040000000001 lambda= 0.0\n",
      "Total PID Loss 1.5042250000000001 lambda= 0.0\n",
      "Total PID Loss 1.4719639999999998 lambda= 0.0\n",
      "Total PID Loss 1.419601 lambda= 0.0\n",
      "Total PID Loss 1.4377490000000013 lambda= 0.0\n",
      "Total PID Loss 1.404 lambda= 0.0\n",
      "Total PID Loss 1.3998490000000003 lambda= 0.0\n",
      "Total PID Loss 1.2970090000000003 lambda= 0.0\n",
      "Total PID Loss 1.4545690000000018 lambda= 0.0\n",
      "Total PID Loss 1.368041000000001 lambda= 0.0\n",
      "Total PID Loss 1.3570359999999995 lambda= 0.0\n",
      "Total PID Loss 1.4931249999999996 lambda= 0.0\n",
      "Total PID Loss 1.3526159999999996 lambda= 0.0\n",
      "Total PID Loss 1.3240239999999999 lambda= 0.0\n",
      "Total PID Loss 1.461995999999999 lambda= 0.0\n",
      "Total PID Loss 1.2746359999999997 lambda= 0.0\n",
      "Total PID Loss 1.5375159999999988 lambda= 0.0\n",
      "Total PID Loss 1.2835610000000004 lambda= 0.0\n",
      "Total PID Loss 1.4476439999999995 lambda= 0.0\n",
      "Total PID Loss 1.2964639999999998 lambda= 0.0\n",
      "Total PID Loss 1.3576409999999992 lambda= 0.0\n",
      "Total PID Loss 1.2805160000000004 lambda= 0.0\n",
      "Total PID Loss 1.250296 lambda= 0.0\n",
      "Total PID Loss 1.235725 lambda= 0.0\n",
      "Total PID Loss 1.252289 lambda= 0.0\n",
      "Total PID Loss 1.3414489999999994 lambda= 0.0\n",
      "Total PID Loss 1.254269 lambda= 0.0\n",
      "Total PID Loss 1.2219840000000002 lambda= 0.0\n",
      "Total PID Loss 1.208161 lambda= 0.0\n",
      "Total PID Loss 1.212125 lambda= 0.0\n",
      "Total PID Loss 1.2299489999999993 lambda= 0.0\n",
      "Total PID Loss 1.2165689999999998 lambda= 0.0\n",
      "Total PID Loss 1.2462210000000005 lambda= 0.0\n",
      "Total PID Loss 1.2179689999999999 lambda= 0.0\n",
      "Total PID Loss 1.2902249999999995 lambda= 0.0\n",
      "Total PID Loss 1.2046559999999997 lambda= 0.0\n",
      "Total PID Loss 1.1978410000000002 lambda= 0.0\n",
      "Total PID Loss 1.2059890000000002 lambda= 0.0\n",
      "Total PID Loss 1.2241360000000006 lambda= 0.0\n",
      "Total PID Loss 1.206104 lambda= 0.0\n",
      "Total PID Loss 1.2024959999999998 lambda= 0.0\n",
      "Total PID Loss 1.2002240000000002 lambda= 0.0\n",
      "Total PID Loss 1.2263000000000004 lambda= 0.0\n",
      "Total PID Loss 1.199504 lambda= 0.0\n",
      "Total PID Loss 1.197325 lambda= 0.0\n",
      "Total PID Loss 1.2033 lambda= 0.0\n",
      "Total PID Loss 1.196464 lambda= 0.0\n",
      "Total PID Loss 1.200001 lambda= 0.0\n",
      "Total PID Loss 1.201916 lambda= 0.0\n",
      "Total PID Loss 1.197104 lambda= 0.0\n",
      "Total PID Loss 1.2008889999999997 lambda= 0.0\n",
      "Total PID Loss 1.197244 lambda= 0.0\n",
      "Total PID Loss 1.196124 lambda= 0.0\n",
      "Total PID Loss 1.1985009999999998 lambda= 0.0\n",
      "Total PID Loss 1.197669 lambda= 0.0\n",
      "Total PID Loss 1.1961959999999998 lambda= 0.0\n",
      "Total PID Loss 1.1981490000000004 lambda= 0.0\n",
      "Total PID Loss 1.196289 lambda= 0.0\n",
      "Total PID Loss 1.196381 lambda= 0.0\n",
      "Total PID Loss 1.1966250000000003 lambda= 0.0\n",
      "Total PID Loss 1.195925 lambda= 0.0\n",
      "Total PID Loss 1.1975160000000002 lambda= 0.0\n",
      "Total PID Loss 1.195836 lambda= 0.0\n",
      "Total PID Loss 1.196341 lambda= 0.0\n",
      "Total PID Loss 1.195889 lambda= 0.0\n",
      "Total PID Loss 1.196249 lambda= 0.0\n",
      "Total PID Loss 1.195825 lambda= 0.0\n",
      "Total PID Loss 1.196601 lambda= 0.0\n",
      "Total PID Loss 1.1957840000000002 lambda= 0.0\n",
      "Total PID Loss 1.1960000000000002 lambda= 0.0\n",
      "Total PID Loss 1.195821 lambda= 0.0\n",
      "Total PID Loss 1.195856 lambda= 0.0\n",
      "Total PID Loss 1.195756 lambda= 0.0\n",
      "Total PID Loss 1.195961 lambda= 0.0\n",
      "Total PID Loss 1.195744 lambda= 0.0\n",
      "Total PID Loss 1.195925 lambda= 0.0\n",
      "Total PID Loss 1.1958 lambda= 0.0\n",
      "Total PID Loss 1.195925 lambda= 0.0\n",
      "Total PID Loss 1.195796 lambda= 0.0\n",
      "Total PID Loss 1.195744 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195756 lambda= 0.0\n",
      "Total PID Loss 1.195836 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.1957689999999999 lambda= 0.0\n",
      "Total PID Loss 1.195725 lambda= 0.0\n",
      "Total PID Loss 1.1957689999999999 lambda= 0.0\n",
      "Total PID Loss 1.195725 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.1958840000000002 lambda= 0.0\n",
      "Total PID Loss 1.195825 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195725 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195789 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195824 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.195724 lambda= 0.0\n",
      "Total PID Loss 1.1923865 lambda= 0.125\n",
      "Total PID Loss 1.192459 lambda= 0.125\n",
      "Total PID Loss 1.1924615 lambda= 0.125\n",
      "Total PID Loss 1.7785784999999996 lambda= 0.125\n",
      "Total PID Loss 1.1925510000000001 lambda= 0.125\n",
      "Total PID Loss 1.7708159999999982 lambda= 0.125\n",
      "Total PID Loss 1.3376515000000007 lambda= 0.125\n",
      "Total PID Loss 1.3385910000000005 lambda= 0.125\n",
      "Total PID Loss 1.2284884999999994 lambda= 0.125\n",
      "Total PID Loss 1.2288999999999992 lambda= 0.125\n",
      "Total PID Loss 1.2013985 lambda= 0.125\n",
      "Total PID Loss 1.2015749999999998 lambda= 0.125\n",
      "Total PID Loss 1.194606 lambda= 0.125\n",
      "Total PID Loss 1.1947065000000001 lambda= 0.125\n",
      "Total PID Loss 1.1929499999999997 lambda= 0.125\n",
      "Total PID Loss 1.1929065 lambda= 0.125\n",
      "Total PID Loss 1.1924885 lambda= 0.125\n",
      "Total PID Loss 1.1922375 lambda= 0.125\n",
      "Total PID Loss 1.1924035 lambda= 0.125\n",
      "Total PID Loss 1.192624 lambda= 0.125\n",
      "Total PID Loss 1.192374 lambda= 0.125\n",
      "Total PID Loss 1.1922885 lambda= 0.125\n",
      "Total PID Loss 1.1925125 lambda= 0.125\n",
      "Total PID Loss 1.192291 lambda= 0.125\n",
      "Total PID Loss 1.1923715000000001 lambda= 0.125\n",
      "Total PID Loss 1.192846 lambda= 0.125\n",
      "Total PID Loss 1.1922375 lambda= 0.125\n",
      "Total PID Loss 1.1923834999999998 lambda= 0.125\n",
      "Total PID Loss 1.192276 lambda= 0.125\n",
      "Total PID Loss 1.19225 lambda= 0.125\n",
      "Total PID Loss 1.1922059999999999 lambda= 0.125\n",
      "Total PID Loss 1.192169 lambda= 0.125\n",
      "Total PID Loss 1.192231 lambda= 0.125\n",
      "Total PID Loss 1.192314 lambda= 0.125\n",
      "Total PID Loss 1.1921765 lambda= 0.125\n",
      "Total PID Loss 1.1922335 lambda= 0.125\n",
      "Total PID Loss 1.1922115 lambda= 0.125\n",
      "Total PID Loss 1.1922685 lambda= 0.125\n",
      "Total PID Loss 1.192169 lambda= 0.125\n",
      "Total PID Loss 1.1921374999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921115 lambda= 0.125\n",
      "Total PID Loss 1.192304 lambda= 0.125\n",
      "Total PID Loss 1.1922085 lambda= 0.125\n",
      "Total PID Loss 1.192211 lambda= 0.125\n",
      "Total PID Loss 1.192219 lambda= 0.125\n",
      "Total PID Loss 1.1921374999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921374999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921365 lambda= 0.125\n",
      "Total PID Loss 1.1921374999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921985 lambda= 0.125\n",
      "Total PID Loss 1.1921059999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921115 lambda= 0.125\n",
      "Total PID Loss 1.192161 lambda= 0.125\n",
      "Total PID Loss 1.192181 lambda= 0.125\n",
      "Total PID Loss 1.1921515 lambda= 0.125\n",
      "Total PID Loss 1.1921515 lambda= 0.125\n",
      "Total PID Loss 1.192164 lambda= 0.125\n",
      "Total PID Loss 1.1921249999999999 lambda= 0.125\n",
      "Total PID Loss 1.1920935 lambda= 0.125\n",
      "Total PID Loss 1.1921125 lambda= 0.125\n",
      "Total PID Loss 1.1921374999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921709999999999 lambda= 0.125\n",
      "Total PID Loss 1.192181 lambda= 0.125\n",
      "Total PID Loss 1.1921059999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921059999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921249999999999 lambda= 0.125\n",
      "Total PID Loss 1.192181 lambda= 0.125\n",
      "Total PID Loss 1.1921374999999999 lambda= 0.125\n",
      "Total PID Loss 1.1921249999999999 lambda= 0.125\n",
      "Total PID Loss 1.1920935 lambda= 0.125\n",
      "Total PID Loss 1.192181 lambda= 0.125\n",
      "Total PID Loss 1.1921059999999999 lambda= 0.125\n",
      "Total PID Loss 1.1920935 lambda= 0.125\n",
      "Total PID Loss 1.192181 lambda= 0.125\n",
      "Total PID Loss 1.1921059999999999 lambda= 0.125\n",
      "Total PID Loss 1.1920935 lambda= 0.125\n",
      "Total PID Loss 1.1920935 lambda= 0.125\n",
      "Total PID Loss 1.1920935 lambda= 0.125\n",
      "Total PID Loss 1.1921059999999999 lambda= 0.125\n",
      "Total PID Loss 1.188506 lambda= 0.25\n",
      "Total PID Loss 1.188621 lambda= 0.25\n",
      "Total PID Loss 1.188506 lambda= 0.25\n",
      "Total PID Loss 1.765666000000001 lambda= 0.25\n",
      "Total PID Loss 1.1885750000000002 lambda= 0.25\n",
      "Total PID Loss 1.775741000000002 lambda= 0.25\n",
      "Total PID Loss 1.3293690000000002 lambda= 0.25\n",
      "Total PID Loss 1.338225 lambda= 0.25\n",
      "Total PID Loss 1.2223909999999991 lambda= 0.25\n",
      "Total PID Loss 1.2272500000000002 lambda= 0.25\n",
      "Total PID Loss 1.196451 lambda= 0.25\n",
      "Total PID Loss 1.198775 lambda= 0.25\n",
      "Total PID Loss 1.190134 lambda= 0.25\n",
      "Total PID Loss 1.191364 lambda= 0.25\n",
      "Total PID Loss 1.188766 lambda= 0.25\n",
      "Total PID Loss 1.189324 lambda= 0.25\n",
      "Total PID Loss 1.1884139999999999 lambda= 0.25\n",
      "Total PID Loss 1.1897440000000001 lambda= 0.25\n",
      "Total PID Loss 1.188401 lambda= 0.25\n",
      "Total PID Loss 1.1883339999999998 lambda= 0.25\n",
      "Total PID Loss 1.188354 lambda= 0.25\n",
      "Total PID Loss 1.1882609999999998 lambda= 0.25\n",
      "Total PID Loss 1.188225 lambda= 0.25\n",
      "Total PID Loss 1.188116 lambda= 0.25\n",
      "Total PID Loss 1.188029 lambda= 0.25\n",
      "Total PID Loss 1.1885210000000002 lambda= 0.25\n",
      "Total PID Loss 1.188275 lambda= 0.25\n",
      "Total PID Loss 1.188056 lambda= 0.25\n",
      "Total PID Loss 1.187946 lambda= 0.25\n",
      "Total PID Loss 1.187825 lambda= 0.25\n",
      "Total PID Loss 1.187824 lambda= 0.25\n",
      "Total PID Loss 1.187739 lambda= 0.25\n",
      "Total PID Loss 1.187746 lambda= 0.25\n",
      "Total PID Loss 1.1879439999999999 lambda= 0.25\n",
      "Total PID Loss 1.188329 lambda= 0.25\n",
      "Total PID Loss 1.187799 lambda= 0.25\n",
      "Total PID Loss 1.187921 lambda= 0.25\n",
      "Total PID Loss 1.187846 lambda= 0.25\n",
      "Total PID Loss 1.187819 lambda= 0.25\n",
      "Total PID Loss 1.187886 lambda= 0.25\n",
      "Total PID Loss 1.1878190000000002 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.187786 lambda= 0.25\n",
      "Total PID Loss 1.1878440000000001 lambda= 0.25\n",
      "Total PID Loss 1.187814 lambda= 0.25\n",
      "Total PID Loss 1.1877460000000002 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.187799 lambda= 0.25\n",
      "Total PID Loss 1.187774 lambda= 0.25\n",
      "Total PID Loss 1.1878250000000001 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.187775 lambda= 0.25\n",
      "Total PID Loss 1.1878140000000001 lambda= 0.25\n",
      "Total PID Loss 1.187781 lambda= 0.25\n",
      "Total PID Loss 1.187789 lambda= 0.25\n",
      "Total PID Loss 1.187789 lambda= 0.25\n",
      "Total PID Loss 1.1878140000000001 lambda= 0.25\n",
      "Total PID Loss 1.1878060000000001 lambda= 0.25\n",
      "Total PID Loss 1.187781 lambda= 0.25\n",
      "Total PID Loss 1.187756 lambda= 0.25\n",
      "Total PID Loss 1.1878250000000001 lambda= 0.25\n",
      "Total PID Loss 1.187789 lambda= 0.25\n",
      "Total PID Loss 1.187806 lambda= 0.25\n",
      "Total PID Loss 1.187756 lambda= 0.25\n",
      "Total PID Loss 1.187789 lambda= 0.25\n",
      "Total PID Loss 1.187814 lambda= 0.25\n",
      "Total PID Loss 1.187756 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.1878060000000001 lambda= 0.25\n",
      "Total PID Loss 1.187814 lambda= 0.25\n",
      "Total PID Loss 1.187739 lambda= 0.25\n",
      "Total PID Loss 1.187739 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.187814 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.187739 lambda= 0.25\n",
      "Total PID Loss 1.187814 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.187739 lambda= 0.25\n",
      "Total PID Loss 1.187739 lambda= 0.25\n",
      "Total PID Loss 1.187739 lambda= 0.25\n",
      "Total PID Loss 1.187764 lambda= 0.25\n",
      "Total PID Loss 1.1829765 lambda= 0.375\n",
      "Total PID Loss 1.1830515000000001 lambda= 0.375\n",
      "Total PID Loss 1.183039 lambda= 0.375\n",
      "Total PID Loss 1.7584740000000012 lambda= 0.375\n",
      "Total PID Loss 1.1830565 lambda= 0.375\n",
      "Total PID Loss 1.7640165000000008 lambda= 0.375\n",
      "Total PID Loss 1.3246334999999994 lambda= 0.375\n",
      "Total PID Loss 1.3304135000000004 lambda= 0.375\n",
      "Total PID Loss 1.2173125000000002 lambda= 0.375\n",
      "Total PID Loss 1.2209 lambda= 0.375\n",
      "Total PID Loss 1.191075 lambda= 0.375\n",
      "Total PID Loss 1.1928874999999999 lambda= 0.375\n",
      "Total PID Loss 1.1847415 lambda= 0.375\n",
      "Total PID Loss 1.1857115 lambda= 0.375\n",
      "Total PID Loss 1.1832785000000001 lambda= 0.375\n",
      "Total PID Loss 1.1837235 lambda= 0.375\n",
      "Total PID Loss 1.1829765 lambda= 0.375\n",
      "Total PID Loss 1.182901 lambda= 0.375\n",
      "Total PID Loss 1.1830015 lambda= 0.375\n",
      "Total PID Loss 1.183501 lambda= 0.375\n",
      "Total PID Loss 1.182901 lambda= 0.375\n",
      "Total PID Loss 1.1828035 lambda= 0.375\n",
      "Total PID Loss 1.1827290000000001 lambda= 0.375\n",
      "Total PID Loss 1.183169 lambda= 0.375\n",
      "Total PID Loss 1.1828935 lambda= 0.375\n",
      "Total PID Loss 1.1827415000000001 lambda= 0.375\n",
      "Total PID Loss 1.1826660000000002 lambda= 0.375\n",
      "Total PID Loss 1.1825615 lambda= 0.375\n",
      "Total PID Loss 1.182625 lambda= 0.375\n",
      "Total PID Loss 1.1826135 lambda= 0.375\n",
      "Total PID Loss 1.182594 lambda= 0.375\n",
      "Total PID Loss 1.182571 lambda= 0.375\n",
      "Total PID Loss 1.1825115 lambda= 0.375\n",
      "Total PID Loss 1.1825615 lambda= 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 1.182636 lambda= 0.375\n",
      "Total PID Loss 1.1826109999999999 lambda= 0.375\n",
      "Total PID Loss 1.182571 lambda= 0.375\n",
      "Total PID Loss 1.182506 lambda= 0.375\n",
      "Total PID Loss 1.1825139999999998 lambda= 0.375\n",
      "Total PID Loss 1.1825785 lambda= 0.375\n",
      "Total PID Loss 1.1825565 lambda= 0.375\n",
      "Total PID Loss 1.1825535 lambda= 0.375\n",
      "Total PID Loss 1.1825375 lambda= 0.375\n",
      "Total PID Loss 1.1825465 lambda= 0.375\n",
      "Total PID Loss 1.182669 lambda= 0.375\n",
      "Total PID Loss 1.18255 lambda= 0.375\n",
      "Total PID Loss 1.182575 lambda= 0.375\n",
      "Total PID Loss 1.1825235 lambda= 0.375\n",
      "Total PID Loss 1.1825565 lambda= 0.375\n",
      "Total PID Loss 1.1825485 lambda= 0.375\n",
      "Total PID Loss 1.182539 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182531 lambda= 0.375\n",
      "Total PID Loss 1.1824985 lambda= 0.375\n",
      "Total PID Loss 1.1825015 lambda= 0.375\n",
      "Total PID Loss 1.1825109999999999 lambda= 0.375\n",
      "Total PID Loss 1.1825115 lambda= 0.375\n",
      "Total PID Loss 1.182524 lambda= 0.375\n",
      "Total PID Loss 1.182514 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.1825015 lambda= 0.375\n",
      "Total PID Loss 1.182506 lambda= 0.375\n",
      "Total PID Loss 1.182506 lambda= 0.375\n",
      "Total PID Loss 1.1825685 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182514 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182514 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.1825014999999999 lambda= 0.375\n",
      "Total PID Loss 1.1825265 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182514 lambda= 0.375\n",
      "Total PID Loss 1.1825265 lambda= 0.375\n",
      "Total PID Loss 1.1825515 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.1825515 lambda= 0.375\n",
      "Total PID Loss 1.1825265 lambda= 0.375\n",
      "Total PID Loss 1.182489 lambda= 0.375\n",
      "Total PID Loss 1.176564 lambda= 0.5\n",
      "Total PID Loss 1.176266 lambda= 0.5\n",
      "Total PID Loss 1.1766139999999998 lambda= 0.5\n",
      "Total PID Loss 1.7520559999999974 lambda= 0.5\n",
      "Total PID Loss 1.1765940000000001 lambda= 0.5\n",
      "Total PID Loss 1.7481039999999992 lambda= 0.5\n",
      "Total PID Loss 1.3207339999999999 lambda= 0.5\n",
      "Total PID Loss 1.3189750000000013 lambda= 0.5\n",
      "Total PID Loss 1.2116250000000002 lambda= 0.5\n",
      "Total PID Loss 1.2132060000000005 lambda= 0.5\n",
      "Total PID Loss 1.1850000000000003 lambda= 0.5\n",
      "Total PID Loss 1.185821 lambda= 0.5\n",
      "Total PID Loss 1.178509 lambda= 0.5\n",
      "Total PID Loss 1.178964 lambda= 0.5\n",
      "Total PID Loss 1.176891 lambda= 0.5\n",
      "Total PID Loss 1.177124 lambda= 0.5\n",
      "Total PID Loss 1.176539 lambda= 0.5\n",
      "Total PID Loss 1.176281 lambda= 0.5\n",
      "Total PID Loss 1.176209 lambda= 0.5\n",
      "Total PID Loss 1.1760510000000002 lambda= 0.5\n",
      "Total PID Loss 1.175916 lambda= 0.5\n",
      "Total PID Loss 1.1758359999999999 lambda= 0.5\n",
      "Total PID Loss 1.1761 lambda= 0.5\n",
      "Total PID Loss 1.1761 lambda= 0.5\n",
      "Total PID Loss 1.175851 lambda= 0.5\n",
      "Total PID Loss 1.175899 lambda= 0.5\n",
      "Total PID Loss 1.175846 lambda= 0.5\n",
      "Total PID Loss 1.175939 lambda= 0.5\n",
      "Total PID Loss 1.175821 lambda= 0.5\n",
      "Total PID Loss 1.1758709999999999 lambda= 0.5\n",
      "Total PID Loss 1.1757810000000002 lambda= 0.5\n",
      "Total PID Loss 1.1760410000000001 lambda= 0.5\n",
      "Total PID Loss 1.1757749999999998 lambda= 0.5\n",
      "Total PID Loss 1.175909 lambda= 0.5\n",
      "Total PID Loss 1.1757710000000001 lambda= 0.5\n",
      "Total PID Loss 1.175869 lambda= 0.5\n",
      "Total PID Loss 1.175799 lambda= 0.5\n",
      "Total PID Loss 1.175766 lambda= 0.5\n",
      "Total PID Loss 1.175801 lambda= 0.5\n",
      "Total PID Loss 1.175799 lambda= 0.5\n",
      "Total PID Loss 1.175799 lambda= 0.5\n",
      "Total PID Loss 1.1757490000000002 lambda= 0.5\n",
      "Total PID Loss 1.1757659999999999 lambda= 0.5\n",
      "Total PID Loss 1.175786 lambda= 0.5\n",
      "Total PID Loss 1.175786 lambda= 0.5\n",
      "Total PID Loss 1.1757360000000001 lambda= 0.5\n",
      "Total PID Loss 1.1757360000000001 lambda= 0.5\n",
      "Total PID Loss 1.175716 lambda= 0.5\n",
      "Total PID Loss 1.1757659999999999 lambda= 0.5\n",
      "Total PID Loss 1.175749 lambda= 0.5\n",
      "Total PID Loss 1.175764 lambda= 0.5\n",
      "Total PID Loss 1.1757490000000002 lambda= 0.5\n",
      "Total PID Loss 1.1757749999999998 lambda= 0.5\n",
      "Total PID Loss 1.1757360000000001 lambda= 0.5\n",
      "Total PID Loss 1.1757659999999999 lambda= 0.5\n",
      "Total PID Loss 1.1757490000000002 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175725 lambda= 0.5\n",
      "Total PID Loss 1.1757360000000001 lambda= 0.5\n",
      "Total PID Loss 1.1757360000000001 lambda= 0.5\n",
      "Total PID Loss 1.175786 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175725 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175725 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175725 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175725 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175725 lambda= 0.5\n",
      "Total PID Loss 1.175725 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.175775 lambda= 0.5\n",
      "Total PID Loss 1.167891 lambda= 0.625\n",
      "Total PID Loss 1.167176 lambda= 0.625\n",
      "Total PID Loss 1.1679285000000001 lambda= 0.625\n",
      "Total PID Loss 1.7344889999999986 lambda= 0.625\n",
      "Total PID Loss 1.1680015 lambda= 0.625\n",
      "Total PID Loss 1.7267890000000012 lambda= 0.625\n",
      "Total PID Loss 1.3087749999999994 lambda= 0.625\n",
      "Total PID Loss 1.3081249999999993 lambda= 0.625\n",
      "Total PID Loss 1.2025640000000002 lambda= 0.625\n",
      "Total PID Loss 1.203264 lambda= 0.625\n",
      "Total PID Loss 1.1762914999999998 lambda= 0.625\n",
      "Total PID Loss 1.1768125 lambda= 0.625\n",
      "Total PID Loss 1.1698009999999996 lambda= 0.625\n",
      "Total PID Loss 1.1701115 lambda= 0.625\n",
      "Total PID Loss 1.168259 lambda= 0.625\n",
      "Total PID Loss 1.1683485 lambda= 0.625\n",
      "Total PID Loss 1.1678184999999999 lambda= 0.625\n",
      "Total PID Loss 1.1674410000000002 lambda= 0.625\n",
      "Total PID Loss 1.167239 lambda= 0.625\n",
      "Total PID Loss 1.1669565 lambda= 0.625\n",
      "Total PID Loss 1.1666865 lambda= 0.625\n",
      "Total PID Loss 1.166554 lambda= 0.625\n",
      "Total PID Loss 1.166225 lambda= 0.625\n",
      "Total PID Loss 1.1662815 lambda= 0.625\n",
      "Total PID Loss 1.166096 lambda= 0.625\n",
      "Total PID Loss 1.1662415 lambda= 0.625\n",
      "Total PID Loss 1.1666115000000001 lambda= 0.625\n",
      "Total PID Loss 1.1660625 lambda= 0.625\n",
      "Total PID Loss 1.1667290000000001 lambda= 0.625\n",
      "Total PID Loss 1.166646 lambda= 0.625\n",
      "Total PID Loss 1.1661875 lambda= 0.625\n",
      "Total PID Loss 1.1659959999999998 lambda= 0.625\n",
      "Total PID Loss 1.1663785 lambda= 0.625\n",
      "Total PID Loss 1.1670085 lambda= 0.625\n",
      "Total PID Loss 1.1659735 lambda= 0.625\n",
      "Total PID Loss 1.1659540000000002 lambda= 0.625\n",
      "Total PID Loss 1.1660615 lambda= 0.625\n",
      "Total PID Loss 1.1660125 lambda= 0.625\n",
      "Total PID Loss 1.165976 lambda= 0.625\n",
      "Total PID Loss 1.166116 lambda= 0.625\n",
      "Total PID Loss 1.1659115 lambda= 0.625\n",
      "Total PID Loss 1.1660985 lambda= 0.625\n",
      "Total PID Loss 1.1659514999999998 lambda= 0.625\n",
      "Total PID Loss 1.1659815 lambda= 0.625\n",
      "Total PID Loss 1.165929 lambda= 0.625\n",
      "Total PID Loss 1.1659860000000002 lambda= 0.625\n",
      "Total PID Loss 1.1659625 lambda= 0.625\n",
      "Total PID Loss 1.1659375 lambda= 0.625\n",
      "Total PID Loss 1.165956 lambda= 0.625\n",
      "Total PID Loss 1.1659535 lambda= 0.625\n",
      "Total PID Loss 1.1659365 lambda= 0.625\n",
      "Total PID Loss 1.165954 lambda= 0.625\n",
      "Total PID Loss 1.1659365 lambda= 0.625\n",
      "Total PID Loss 1.1658865 lambda= 0.625\n",
      "Total PID Loss 1.1659515 lambda= 0.625\n",
      "Total PID Loss 1.1659160000000002 lambda= 0.625\n",
      "Total PID Loss 1.165984 lambda= 0.625\n",
      "Total PID Loss 1.165961 lambda= 0.625\n",
      "Total PID Loss 1.165949 lambda= 0.625\n",
      "Total PID Loss 1.1659249999999999 lambda= 0.625\n",
      "Total PID Loss 1.165916 lambda= 0.625\n",
      "Total PID Loss 1.1659115 lambda= 0.625\n",
      "Total PID Loss 1.1659249999999999 lambda= 0.625\n",
      "Total PID Loss 1.1659249999999999 lambda= 0.625\n",
      "Total PID Loss 1.165936 lambda= 0.625\n",
      "Total PID Loss 1.165886 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 1.165961 lambda= 0.625\n",
      "Total PID Loss 1.165911 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659 lambda= 0.625\n",
      "Total PID Loss 1.165961 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.165961 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659375 lambda= 0.625\n",
      "Total PID Loss 1.1659485 lambda= 0.625\n",
      "Total PID Loss 1.1659359999999999 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1658875 lambda= 0.625\n",
      "Total PID Loss 1.165911 lambda= 0.625\n",
      "Total PID Loss 1.1659375 lambda= 0.625\n",
      "Total PID Loss 1.1658985 lambda= 0.625\n",
      "Total PID Loss 1.165911 lambda= 0.625\n",
      "Total PID Loss 1.1659359999999999 lambda= 0.625\n",
      "Total PID Loss 1.1659125000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1658985 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1658985 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.165886 lambda= 0.625\n",
      "Total PID Loss 1.1659235000000001 lambda= 0.625\n",
      "Total PID Loss 1.153636 lambda= 0.75\n",
      "Total PID Loss 1.1528040000000002 lambda= 0.75\n",
      "Total PID Loss 1.153661 lambda= 0.75\n",
      "Total PID Loss 1.7041250000000014 lambda= 0.75\n",
      "Total PID Loss 1.153756 lambda= 0.75\n",
      "Total PID Loss 1.6690749999999999 lambda= 0.75\n",
      "Total PID Loss 1.2808160000000006 lambda= 0.75\n",
      "Total PID Loss 1.2925009999999983 lambda= 0.75\n",
      "Total PID Loss 1.1839340000000003 lambda= 0.75\n",
      "Total PID Loss 1.1894739999999993 lambda= 0.75\n",
      "Total PID Loss 1.160386 lambda= 0.75\n",
      "Total PID Loss 1.1631040000000001 lambda= 0.75\n",
      "Total PID Loss 1.154725 lambda= 0.75\n",
      "Total PID Loss 1.1561359999999996 lambda= 0.75\n",
      "Total PID Loss 1.1535939999999998 lambda= 0.75\n",
      "Total PID Loss 1.152829 lambda= 0.75\n",
      "Total PID Loss 1.152416 lambda= 0.75\n",
      "Total PID Loss 1.151916 lambda= 0.75\n",
      "Total PID Loss 1.151661 lambda= 0.75\n",
      "Total PID Loss 1.150896 lambda= 0.75\n",
      "Total PID Loss 1.151919 lambda= 0.75\n",
      "Total PID Loss 1.1517890000000002 lambda= 0.75\n",
      "Total PID Loss 1.150689 lambda= 0.75\n",
      "Total PID Loss 1.151775 lambda= 0.75\n",
      "Total PID Loss 1.15055 lambda= 0.75\n",
      "Total PID Loss 1.1505960000000002 lambda= 0.75\n",
      "Total PID Loss 1.152025 lambda= 0.75\n",
      "Total PID Loss 1.1511460000000002 lambda= 0.75\n",
      "Total PID Loss 1.1509939999999999 lambda= 0.75\n",
      "Total PID Loss 1.149964 lambda= 0.75\n",
      "Total PID Loss 1.149546 lambda= 0.75\n",
      "Total PID Loss 1.151286 lambda= 0.75\n",
      "Total PID Loss 1.1504249999999998 lambda= 0.75\n",
      "Total PID Loss 1.149614 lambda= 0.75\n",
      "Total PID Loss 1.150575 lambda= 0.75\n",
      "Total PID Loss 1.150074 lambda= 0.75\n",
      "Total PID Loss 1.149281 lambda= 0.75\n",
      "Total PID Loss 1.149111 lambda= 0.75\n",
      "Total PID Loss 1.14955 lambda= 0.75\n",
      "Total PID Loss 1.1514609999999996 lambda= 0.75\n",
      "Total PID Loss 1.149459 lambda= 0.75\n",
      "Total PID Loss 1.148996 lambda= 0.75\n",
      "Total PID Loss 1.1489639999999999 lambda= 0.75\n",
      "Total PID Loss 1.1495360000000001 lambda= 0.75\n",
      "Total PID Loss 1.148799 lambda= 0.75\n",
      "Total PID Loss 1.148844 lambda= 0.75\n",
      "Total PID Loss 1.14975 lambda= 0.75\n",
      "Total PID Loss 1.1491510000000003 lambda= 0.75\n",
      "Total PID Loss 1.1494250000000001 lambda= 0.75\n",
      "Total PID Loss 1.148949 lambda= 0.75\n",
      "Total PID Loss 1.1499190000000001 lambda= 0.75\n",
      "Total PID Loss 1.148949 lambda= 0.75\n",
      "Total PID Loss 1.148761 lambda= 0.75\n",
      "Total PID Loss 1.148729 lambda= 0.75\n",
      "Total PID Loss 1.148809 lambda= 0.75\n",
      "Total PID Loss 1.1488 lambda= 0.75\n",
      "Total PID Loss 1.1489690000000001 lambda= 0.75\n",
      "Total PID Loss 1.148771 lambda= 0.75\n",
      "Total PID Loss 1.148939 lambda= 0.75\n",
      "Total PID Loss 1.148729 lambda= 0.75\n",
      "Total PID Loss 1.148916 lambda= 0.75\n",
      "Total PID Loss 1.148699 lambda= 0.75\n",
      "Total PID Loss 1.148774 lambda= 0.75\n",
      "Total PID Loss 1.148711 lambda= 0.75\n",
      "Total PID Loss 1.1487790000000002 lambda= 0.75\n",
      "Total PID Loss 1.148749 lambda= 0.75\n",
      "Total PID Loss 1.148726 lambda= 0.75\n",
      "Total PID Loss 1.148764 lambda= 0.75\n",
      "Total PID Loss 1.1487090000000002 lambda= 0.75\n",
      "Total PID Loss 1.148686 lambda= 0.75\n",
      "Total PID Loss 1.148764 lambda= 0.75\n",
      "Total PID Loss 1.1487500000000002 lambda= 0.75\n",
      "Total PID Loss 1.148709 lambda= 0.75\n",
      "Total PID Loss 1.1486910000000001 lambda= 0.75\n",
      "Total PID Loss 1.1487239999999999 lambda= 0.75\n",
      "Total PID Loss 1.148741 lambda= 0.75\n",
      "Total PID Loss 1.148725 lambda= 0.75\n",
      "Total PID Loss 1.148686 lambda= 0.75\n",
      "Total PID Loss 1.148691 lambda= 0.75\n",
      "Total PID Loss 1.148691 lambda= 0.75\n",
      "Total PID Loss 1.148736 lambda= 0.75\n",
      "Total PID Loss 1.14875 lambda= 0.75\n",
      "Total PID Loss 1.148711 lambda= 0.75\n",
      "Total PID Loss 1.148675 lambda= 0.75\n",
      "Total PID Loss 1.148725 lambda= 0.75\n",
      "Total PID Loss 1.148725 lambda= 0.75\n",
      "Total PID Loss 1.148711 lambda= 0.75\n",
      "Total PID Loss 1.148711 lambda= 0.75\n",
      "Total PID Loss 1.148686 lambda= 0.75\n",
      "Total PID Loss 1.1487360000000002 lambda= 0.75\n",
      "Total PID Loss 1.148736 lambda= 0.75\n",
      "Total PID Loss 1.148725 lambda= 0.75\n",
      "Total PID Loss 1.148736 lambda= 0.75\n",
      "Total PID Loss 1.1487360000000002 lambda= 0.75\n",
      "Total PID Loss 1.1487249999999998 lambda= 0.75\n",
      "Total PID Loss 1.1487249999999998 lambda= 0.75\n",
      "Total PID Loss 1.1487500000000002 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1487249999999998 lambda= 0.75\n",
      "Total PID Loss 1.1487249999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1487249999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1487500000000002 lambda= 0.75\n",
      "Total PID Loss 1.1487249999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1487500000000002 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1486999999999998 lambda= 0.75\n",
      "Total PID Loss 1.1241999999999999 lambda= 0.875\n",
      "Total PID Loss 1.128431 lambda= 0.875\n",
      "Total PID Loss 1.1242234999999998 lambda= 0.875\n",
      "Total PID Loss 1.6110290000000007 lambda= 0.875\n",
      "Total PID Loss 1.1243115000000001 lambda= 0.875\n",
      "Total PID Loss 1.527683499999999 lambda= 0.875\n",
      "Total PID Loss 1.2175490000000002 lambda= 0.875\n",
      "Total PID Loss 1.2532749999999995 lambda= 0.875\n",
      "Total PID Loss 1.1435390000000005 lambda= 0.875\n",
      "Total PID Loss 1.1604640000000002 lambda= 0.875\n",
      "Total PID Loss 1.1269435 lambda= 0.875\n",
      "Total PID Loss 1.1361965000000003 lambda= 0.875\n",
      "Total PID Loss 1.124021 lambda= 0.875\n",
      "Total PID Loss 1.1315709999999999 lambda= 0.875\n",
      "Total PID Loss 1.124204 lambda= 0.875\n",
      "Total PID Loss 1.1231909999999998 lambda= 0.875\n",
      "Total PID Loss 1.1226535000000002 lambda= 0.875\n",
      "Total PID Loss 1.1224109999999998 lambda= 0.875\n",
      "Total PID Loss 1.1216015000000001 lambda= 0.875\n",
      "Total PID Loss 1.124301 lambda= 0.875\n",
      "Total PID Loss 1.1232374999999999 lambda= 0.875\n",
      "Total PID Loss 1.121225 lambda= 0.875\n",
      "Total PID Loss 1.1203640000000001 lambda= 0.875\n",
      "Total PID Loss 1.1208740000000001 lambda= 0.875\n",
      "Total PID Loss 1.119426 lambda= 0.875\n",
      "Total PID Loss 1.1192135 lambda= 0.875\n",
      "Total PID Loss 1.1184865 lambda= 0.875\n",
      "Total PID Loss 1.1213709999999997 lambda= 0.875\n",
      "Total PID Loss 1.1186765 lambda= 0.875\n",
      "Total PID Loss 1.1298039999999998 lambda= 0.875\n",
      "Total PID Loss 1.1188375000000002 lambda= 0.875\n",
      "Total PID Loss 1.1176125 lambda= 0.875\n",
      "Total PID Loss 1.1193889999999997 lambda= 0.875\n",
      "Total PID Loss 1.1166125 lambda= 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 1.1156715 lambda= 0.875\n",
      "Total PID Loss 1.122176 lambda= 0.875\n",
      "Total PID Loss 1.1176875 lambda= 0.875\n",
      "Total PID Loss 1.116619 lambda= 0.875\n",
      "Total PID Loss 1.1151585 lambda= 0.875\n",
      "Total PID Loss 1.114204 lambda= 0.875\n",
      "Total PID Loss 1.1141285 lambda= 0.875\n",
      "Total PID Loss 1.113424 lambda= 0.875\n",
      "Total PID Loss 1.114504 lambda= 0.875\n",
      "Total PID Loss 1.1117540000000001 lambda= 0.875\n",
      "Total PID Loss 1.1120249999999998 lambda= 0.875\n",
      "Total PID Loss 1.1106189999999998 lambda= 0.875\n",
      "Total PID Loss 1.1095435000000002 lambda= 0.875\n",
      "Total PID Loss 1.1150535000000001 lambda= 0.875\n",
      "Total PID Loss 1.1126250000000002 lambda= 0.875\n",
      "Total PID Loss 1.1129 lambda= 0.875\n",
      "Total PID Loss 1.108646 lambda= 0.875\n",
      "Total PID Loss 1.1073335 lambda= 0.875\n",
      "Total PID Loss 1.1135875 lambda= 0.875\n",
      "Total PID Loss 1.110219 lambda= 0.875\n",
      "Total PID Loss 1.1156134999999998 lambda= 0.875\n",
      "Total PID Loss 1.110579 lambda= 0.875\n",
      "Total PID Loss 1.1081375 lambda= 0.875\n",
      "Total PID Loss 1.1137889999999997 lambda= 0.875\n",
      "Total PID Loss 1.1091710000000001 lambda= 0.875\n",
      "Total PID Loss 1.1069814999999998 lambda= 0.875\n",
      "Total PID Loss 1.1060085 lambda= 0.875\n",
      "Total PID Loss 1.1060615 lambda= 0.875\n",
      "Total PID Loss 1.1087765 lambda= 0.875\n",
      "Total PID Loss 1.1065334999999998 lambda= 0.875\n",
      "Total PID Loss 1.1056865 lambda= 0.875\n",
      "Total PID Loss 1.105901 lambda= 0.875\n",
      "Total PID Loss 1.1054000000000002 lambda= 0.875\n",
      "Total PID Loss 1.109659 lambda= 0.875\n",
      "Total PID Loss 1.1061465000000001 lambda= 0.875\n",
      "Total PID Loss 1.1056115000000002 lambda= 0.875\n",
      "Total PID Loss 1.104971 lambda= 0.875\n",
      "Total PID Loss 1.1051410000000002 lambda= 0.875\n",
      "Total PID Loss 1.104439 lambda= 0.875\n",
      "Total PID Loss 1.1044385 lambda= 0.875\n",
      "Total PID Loss 1.1059965 lambda= 0.875\n",
      "Total PID Loss 1.105079 lambda= 0.875\n",
      "Total PID Loss 1.1066875 lambda= 0.875\n",
      "Total PID Loss 1.105001 lambda= 0.875\n",
      "Total PID Loss 1.1052965000000001 lambda= 0.875\n",
      "Total PID Loss 1.1047935 lambda= 0.875\n",
      "Total PID Loss 1.1043889999999998 lambda= 0.875\n",
      "Total PID Loss 1.1049125000000002 lambda= 0.875\n",
      "Total PID Loss 1.104666 lambda= 0.875\n",
      "Total PID Loss 1.104334 lambda= 0.875\n",
      "Total PID Loss 1.106034 lambda= 0.875\n",
      "Total PID Loss 1.108825 lambda= 0.875\n",
      "Total PID Loss 1.1042874999999999 lambda= 0.875\n",
      "Total PID Loss 1.1040985 lambda= 0.875\n",
      "Total PID Loss 1.1042235 lambda= 0.875\n",
      "Total PID Loss 1.104129 lambda= 0.875\n",
      "Total PID Loss 1.103829 lambda= 0.875\n",
      "Total PID Loss 1.1037375 lambda= 0.875\n",
      "Total PID Loss 1.1049115 lambda= 0.875\n",
      "Total PID Loss 1.1039065 lambda= 0.875\n",
      "Total PID Loss 1.1036485 lambda= 0.875\n",
      "Total PID Loss 1.103519 lambda= 0.875\n",
      "Total PID Loss 1.103621 lambda= 0.875\n",
      "Total PID Loss 1.1037215 lambda= 0.875\n",
      "Total PID Loss 1.1034875 lambda= 0.875\n",
      "Total PID Loss 1.1041735 lambda= 0.875\n",
      "Total PID Loss 1.1055635 lambda= 0.875\n",
      "Total PID Loss 1.1034715 lambda= 0.875\n",
      "Total PID Loss 1.1034885 lambda= 0.875\n",
      "Total PID Loss 1.1033625 lambda= 0.875\n",
      "Total PID Loss 1.1033614999999999 lambda= 0.875\n",
      "Total PID Loss 1.1034015 lambda= 0.875\n",
      "Total PID Loss 1.1033035 lambda= 0.875\n",
      "Total PID Loss 1.1034065 lambda= 0.875\n",
      "Total PID Loss 1.1038735000000002 lambda= 0.875\n",
      "Total PID Loss 1.1033485 lambda= 0.875\n",
      "Total PID Loss 1.103251 lambda= 0.875\n",
      "Total PID Loss 1.1035565 lambda= 0.875\n",
      "Total PID Loss 1.103371 lambda= 0.875\n",
      "Total PID Loss 1.103275 lambda= 0.875\n",
      "Total PID Loss 1.103599 lambda= 0.875\n",
      "Total PID Loss 1.103304 lambda= 0.875\n",
      "Total PID Loss 1.1032760000000001 lambda= 0.875\n",
      "Total PID Loss 1.1033875 lambda= 0.875\n",
      "Total PID Loss 1.103276 lambda= 0.875\n",
      "Total PID Loss 1.1033385 lambda= 0.875\n",
      "Total PID Loss 1.103229 lambda= 0.875\n",
      "Total PID Loss 1.103286 lambda= 0.875\n",
      "Total PID Loss 1.10325 lambda= 0.875\n",
      "Total PID Loss 1.10325 lambda= 0.875\n",
      "Total PID Loss 1.103325 lambda= 0.875\n",
      "Total PID Loss 1.1032465000000002 lambda= 0.875\n",
      "Total PID Loss 1.1033 lambda= 0.875\n",
      "Total PID Loss 1.103229 lambda= 0.875\n",
      "Total PID Loss 1.1032635 lambda= 0.875\n",
      "Total PID Loss 1.1032659999999999 lambda= 0.875\n",
      "Total PID Loss 1.1032665000000001 lambda= 0.875\n",
      "Total PID Loss 1.103234 lambda= 0.875\n",
      "Total PID Loss 1.1032760000000001 lambda= 0.875\n",
      "Total PID Loss 1.1032410000000001 lambda= 0.875\n",
      "Total PID Loss 1.103291 lambda= 0.875\n",
      "Total PID Loss 1.1032415000000002 lambda= 0.875\n",
      "Total PID Loss 1.103234 lambda= 0.875\n",
      "Total PID Loss 1.1032285000000002 lambda= 0.875\n",
      "Total PID Loss 1.103275 lambda= 0.875\n",
      "Total PID Loss 1.103284 lambda= 0.875\n",
      "Total PID Loss 1.1032465 lambda= 0.875\n",
      "Total PID Loss 1.1032715 lambda= 0.875\n",
      "Total PID Loss 1.103234 lambda= 0.875\n",
      "Total PID Loss 1.1032410000000001 lambda= 0.875\n",
      "Total PID Loss 1.1032785 lambda= 0.875\n",
      "Total PID Loss 1.1032965000000001 lambda= 0.875\n",
      "Total PID Loss 1.1032410000000001 lambda= 0.875\n",
      "Total PID Loss 1.1032785 lambda= 0.875\n",
      "Total PID Loss 1.1032715000000002 lambda= 0.875\n",
      "Total PID Loss 1.1032410000000001 lambda= 0.875\n",
      "Total PID Loss 1.1032285000000002 lambda= 0.875\n",
      "Total PID Loss 1.1032410000000001 lambda= 0.875\n",
      "Total PID Loss 1.1032535 lambda= 0.875\n",
      "Total PID Loss 1.1032535 lambda= 0.875\n",
      "Total PID Loss 1.1033035 lambda= 0.875\n",
      "Total PID Loss 1.1032285000000002 lambda= 0.875\n",
      "Total PID Loss 1.1032285000000002 lambda= 0.875\n",
      "Total PID Loss 1.1032785 lambda= 0.875\n",
      "Total PID Loss 1.103291 lambda= 0.875\n",
      "Total PID Loss 1.103291 lambda= 0.875\n",
      "Total PID Loss 1.1033035 lambda= 0.875\n",
      "Total PID Loss 1.1032285000000002 lambda= 0.875\n",
      "Total PID Loss 1.1032285000000002 lambda= 0.875\n",
      "Total PID Loss 1.1032535 lambda= 0.875\n",
      "Total PID Loss 1.1033035 lambda= 0.875\n",
      "Total PID Loss 1.015616 lambda= 1.0\n",
      "Total PID Loss 1.145340999999999 lambda= 1.0\n",
      "Total PID Loss 1.015625 lambda= 1.0\n",
      "Total PID Loss 1.2454840000000011 lambda= 1.0\n",
      "Total PID Loss 1.015716 lambda= 1.0\n",
      "Total PID Loss 1.073169 lambda= 1.0\n",
      "Total PID Loss 1.2582000000000002 lambda= 1.0\n",
      "Total PID Loss 1.0330009999999998 lambda= 1.0\n",
      "Total PID Loss 1.159423999999999 lambda= 1.0\n",
      "Total PID Loss 1.0224250000000001 lambda= 1.0\n",
      "Total PID Loss 1.0571040000000003 lambda= 1.0\n",
      "Total PID Loss 1.0159440000000002 lambda= 1.0\n",
      "Total PID Loss 1.0454810000000008 lambda= 1.0\n",
      "Total PID Loss 1.014401 lambda= 1.0\n",
      "Total PID Loss 1.023384 lambda= 1.0\n",
      "Total PID Loss 1.014076 lambda= 1.0\n",
      "Total PID Loss 1.012821 lambda= 1.0\n",
      "Total PID Loss 1.011524 lambda= 1.0\n",
      "Total PID Loss 1.011029 lambda= 1.0\n",
      "Total PID Loss 1.0091560000000002 lambda= 1.0\n",
      "Total PID Loss 1.007969 lambda= 1.0\n",
      "Total PID Loss 1.004401 lambda= 1.0\n",
      "Total PID Loss 1.0054 lambda= 1.0\n",
      "Total PID Loss 1.003554 lambda= 1.0\n",
      "Total PID Loss 1.0003539999999997 lambda= 1.0\n",
      "Total PID Loss 0.9950010000000001 lambda= 1.0\n",
      "Total PID Loss 0.9838200000000001 lambda= 1.0\n",
      "Total PID Loss 0.983915 lambda= 1.0\n",
      "Total PID Loss 0.9787049999999998 lambda= 1.0\n",
      "Total PID Loss 0.958175 lambda= 1.0\n",
      "Total PID Loss 0.9588710000000001 lambda= 1.0\n",
      "Total PID Loss 0.9736049999999996 lambda= 1.0\n",
      "Total PID Loss 0.9724839999999996 lambda= 1.0\n",
      "Total PID Loss 1.128166000000002 lambda= 1.0\n",
      "Total PID Loss 0.96647 lambda= 1.0\n",
      "Total PID Loss 0.965624 lambda= 1.0\n",
      "Total PID Loss 0.990269 lambda= 1.0\n",
      "Total PID Loss 0.9549190000000003 lambda= 1.0\n",
      "Total PID Loss 0.947961 lambda= 1.0\n",
      "Total PID Loss 0.9459059999999997 lambda= 1.0\n",
      "Total PID Loss 0.9729640000000002 lambda= 1.0\n",
      "Total PID Loss 0.955931 lambda= 1.0\n",
      "Total PID Loss 0.9435410000000001 lambda= 1.0\n",
      "Total PID Loss 0.937266 lambda= 1.0\n",
      "Total PID Loss 0.9452890000000003 lambda= 1.0\n",
      "Total PID Loss 0.965245 lambda= 1.0\n",
      "Total PID Loss 0.947469 lambda= 1.0\n",
      "Total PID Loss 0.9294150000000001 lambda= 1.0\n",
      "Total PID Loss 0.9216949999999999 lambda= 1.0\n",
      "Total PID Loss 0.942590999999999 lambda= 1.0\n",
      "Total PID Loss 0.9188289999999999 lambda= 1.0\n",
      "Total PID Loss 0.9119709999999996 lambda= 1.0\n",
      "Total PID Loss 0.9040890000000004 lambda= 1.0\n",
      "Total PID Loss 0.8926489999999998 lambda= 1.0\n",
      "Total PID Loss 0.912229 lambda= 1.0\n",
      "Total PID Loss 0.958879 lambda= 1.0\n",
      "Total PID Loss 0.9187360000000001 lambda= 1.0\n",
      "Total PID Loss 0.8896689999999999 lambda= 1.0\n",
      "Total PID Loss 0.8811640000000002 lambda= 1.0\n",
      "Total PID Loss 0.876324 lambda= 1.0\n",
      "Total PID Loss 0.9431889999999998 lambda= 1.0\n",
      "Total PID Loss 0.9378760000000003 lambda= 1.0\n",
      "Total PID Loss 0.892674 lambda= 1.0\n",
      "Total PID Loss 0.857426 lambda= 1.0\n",
      "Total PID Loss 0.838036 lambda= 1.0\n",
      "Total PID Loss 0.8525659999999999 lambda= 1.0\n",
      "Total PID Loss 0.821845 lambda= 1.0\n",
      "Total PID Loss 0.796636 lambda= 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 0.878375000000001 lambda= 1.0\n",
      "Total PID Loss 0.8353539999999997 lambda= 1.0\n",
      "Total PID Loss 0.789114 lambda= 1.0\n",
      "Total PID Loss 0.790739 lambda= 1.0\n",
      "Total PID Loss 0.7859709999999999 lambda= 1.0\n",
      "Total PID Loss 0.8138460000000005 lambda= 1.0\n",
      "Total PID Loss 0.8069949999999998 lambda= 1.0\n",
      "Total PID Loss 0.8096909999999997 lambda= 1.0\n",
      "Total PID Loss 0.7823709999999999 lambda= 1.0\n",
      "Total PID Loss 0.829934 lambda= 1.0\n",
      "Total PID Loss 0.7876189999999997 lambda= 1.0\n",
      "Total PID Loss 0.7907559999999999 lambda= 1.0\n",
      "Total PID Loss 0.7821899999999999 lambda= 1.0\n",
      "Total PID Loss 0.792091 lambda= 1.0\n",
      "Total PID Loss 0.7834959999999999 lambda= 1.0\n",
      "Total PID Loss 0.7893459999999998 lambda= 1.0\n",
      "Total PID Loss 0.7825810000000001 lambda= 1.0\n",
      "Total PID Loss 0.7901550000000002 lambda= 1.0\n",
      "Total PID Loss 0.7819 lambda= 1.0\n",
      "Total PID Loss 0.785204 lambda= 1.0\n",
      "Total PID Loss 0.781684 lambda= 1.0\n",
      "Total PID Loss 0.7828910000000001 lambda= 1.0\n",
      "Total PID Loss 0.781421 lambda= 1.0\n",
      "Total PID Loss 0.78343 lambda= 1.0\n",
      "Total PID Loss 0.781266 lambda= 1.0\n",
      "Total PID Loss 0.78301 lambda= 1.0\n",
      "Total PID Loss 0.7812709999999999 lambda= 1.0\n",
      "Total PID Loss 0.783034 lambda= 1.0\n",
      "Total PID Loss 0.7812110000000001 lambda= 1.0\n",
      "Total PID Loss 0.781681 lambda= 1.0\n",
      "Total PID Loss 0.781241 lambda= 1.0\n",
      "Total PID Loss 0.7816139999999999 lambda= 1.0\n",
      "Total PID Loss 0.781161 lambda= 1.0\n",
      "Total PID Loss 0.7811560000000001 lambda= 1.0\n",
      "Total PID Loss 0.781449 lambda= 1.0\n",
      "Total PID Loss 0.7812389999999999 lambda= 1.0\n",
      "Total PID Loss 0.781689 lambda= 1.0\n",
      "Total PID Loss 0.781081 lambda= 1.0\n",
      "Total PID Loss 0.781159 lambda= 1.0\n",
      "Total PID Loss 0.78138 lambda= 1.0\n",
      "Total PID Loss 0.781091 lambda= 1.0\n",
      "Total PID Loss 0.781336 lambda= 1.0\n",
      "Total PID Loss 0.781085 lambda= 1.0\n",
      "Total PID Loss 0.781166 lambda= 1.0\n",
      "Total PID Loss 0.781091 lambda= 1.0\n",
      "Total PID Loss 0.7811509999999999 lambda= 1.0\n",
      "Total PID Loss 0.781085 lambda= 1.0\n",
      "Total PID Loss 0.7811039999999999 lambda= 1.0\n",
      "Total PID Loss 0.781081 lambda= 1.0\n",
      "Total PID Loss 0.781185 lambda= 1.0\n",
      "Total PID Loss 0.7810739999999999 lambda= 1.0\n",
      "Total PID Loss 0.78108 lambda= 1.0\n",
      "Total PID Loss 0.781099 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810739999999999 lambda= 1.0\n",
      "Total PID Loss 0.781084 lambda= 1.0\n",
      "Total PID Loss 0.7810739999999999 lambda= 1.0\n",
      "Total PID Loss 0.781075 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810760000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810739999999999 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810739999999999 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810739999999999 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810690000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n",
      "Total PID Loss 0.7810640000000001 lambda= 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m34results = createFrontier(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambdas</th>\n",
       "      <th>inflation_variance</th>\n",
       "      <th>output_gap_variance</th>\n",
       "      <th>interest_variance</th>\n",
       "      <th>loss</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.16860</td>\n",
       "      <td>1.1954</td>\n",
       "      <td>16.018</td>\n",
       "      <td>1.195724</td>\n",
       "      <td>[0.1907884535316938, 0.0034048052145588988, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125</td>\n",
       "      <td>1.16700</td>\n",
       "      <td>1.1956</td>\n",
       "      <td>16.009</td>\n",
       "      <td>1.192106</td>\n",
       "      <td>[0.1972328731233827, 0.003821557120927807, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250</td>\n",
       "      <td>1.15920</td>\n",
       "      <td>1.1972</td>\n",
       "      <td>16.008</td>\n",
       "      <td>1.187764</td>\n",
       "      <td>[0.22964538136658869, 0.0031969847703125593, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375</td>\n",
       "      <td>1.15280</td>\n",
       "      <td>1.2002</td>\n",
       "      <td>16.008</td>\n",
       "      <td>1.182489</td>\n",
       "      <td>[0.2560680754729011, 0.0029694052241527563, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>1.14440</td>\n",
       "      <td>1.2071</td>\n",
       "      <td>16.005</td>\n",
       "      <td>1.175775</td>\n",
       "      <td>[0.2913506186610594, 0.0028552353968771815, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625</td>\n",
       "      <td>1.12910</td>\n",
       "      <td>1.2272</td>\n",
       "      <td>16.006</td>\n",
       "      <td>1.165924</td>\n",
       "      <td>[0.3566639135904265, 0.002844623119750724, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.750</td>\n",
       "      <td>1.09970</td>\n",
       "      <td>1.2956</td>\n",
       "      <td>16.005</td>\n",
       "      <td>1.148700</td>\n",
       "      <td>[0.4817219166106885, 0.0032120173843371066, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.875</td>\n",
       "      <td>1.01570</td>\n",
       "      <td>1.7164</td>\n",
       "      <td>16.004</td>\n",
       "      <td>1.103303</td>\n",
       "      <td>[0.7870056840827763, 0.0034165698249243154, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.78106</td>\n",
       "      <td>6.1947</td>\n",
       "      <td>16.002</td>\n",
       "      <td>0.781064</td>\n",
       "      <td>[1.1176415394101908, 0.005311785425389605, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambdas  inflation_variance  output_gap_variance  interest_variance  \\\n",
       "0    0.000             1.16860               1.1954             16.018   \n",
       "1    0.125             1.16700               1.1956             16.009   \n",
       "2    0.250             1.15920               1.1972             16.008   \n",
       "3    0.375             1.15280               1.2002             16.008   \n",
       "4    0.500             1.14440               1.2071             16.005   \n",
       "5    0.625             1.12910               1.2272             16.006   \n",
       "6    0.750             1.09970               1.2956             16.005   \n",
       "7    0.875             1.01570               1.7164             16.004   \n",
       "8    1.000             0.78106               6.1947             16.002   \n",
       "\n",
       "       loss                                       coefficients  \n",
       "0  1.195724  [0.1907884535316938, 0.0034048052145588988, 0....  \n",
       "1  1.192106  [0.1972328731233827, 0.003821557120927807, 0.9...  \n",
       "2  1.187764  [0.22964538136658869, 0.0031969847703125593, 0...  \n",
       "3  1.182489  [0.2560680754729011, 0.0029694052241527563, 1....  \n",
       "4  1.175775  [0.2913506186610594, 0.0028552353968771815, 1....  \n",
       "5  1.165924  [0.3566639135904265, 0.002844623119750724, 1.0...  \n",
       "6  1.148700  [0.4817219166106885, 0.0032120173843371066, 0....  \n",
       "7  1.103303  [0.7870056840827763, 0.0034165698249243154, 0....  \n",
       "8  0.781064  [1.1176415394101908, 0.005311785425389605, 0.1...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m34results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 1250.757089 lambda= 0.0\n",
      "Total PID Loss 1479.9922639999995 lambda= 0.0\n",
      "Total PID Loss 1251.463549 lambda= 0.0\n",
      "Total PID Loss 1196.8508690000003 lambda= 0.0\n",
      "Total PID Loss 1250.4734409999999 lambda= 0.0\n",
      "Total PID Loss 1021.3620410000002 lambda= 0.0\n",
      "Total PID Loss 831.6499249999998 lambda= 0.0\n",
      "Total PID Loss 1003.7844249999999 lambda= 0.0\n",
      "Total PID Loss 894.969676 lambda= 0.0\n",
      "Total PID Loss 748.0861489999999 lambda= 0.0\n",
      "Total PID Loss 561.5618159999999 lambda= 0.0\n",
      "Total PID Loss 514.3635290000001 lambda= 0.0\n",
      "Total PID Loss 298.93606900000015 lambda= 0.0\n",
      "Total PID Loss 340.18437599999993 lambda= 0.0\n",
      "Total PID Loss 216.80582500000003 lambda= 0.0\n",
      "Total PID Loss 71.4843 lambda= 0.0\n",
      "Total PID Loss 50.457228999999984 lambda= 0.0\n",
      "Total PID Loss 2.1835010000000006 lambda= 0.0\n",
      "Total PID Loss 2.3227209999999996 lambda= 0.0\n",
      "Total PID Loss 7.285164000000003 lambda= 0.0\n",
      "Total PID Loss 1.683749 lambda= 0.0\n",
      "Total PID Loss 28.428448999999993 lambda= 0.0\n",
      "Total PID Loss 3.1065240000000003 lambda= 0.0\n",
      "Total PID Loss 97.06776099999996 lambda= 0.0\n",
      "Total PID Loss 7.686408999999997 lambda= 0.0\n",
      "Total PID Loss 5.929029 lambda= 0.0\n",
      "Total PID Loss 7.749261000000006 lambda= 0.0\n",
      "Total PID Loss 3.619925000000001 lambda= 0.0\n",
      "Total PID Loss 2.4449960000000015 lambda= 0.0\n",
      "Total PID Loss 3.0397289999999977 lambda= 0.0\n",
      "Total PID Loss 1.9780489999999997 lambda= 0.0\n",
      "Total PID Loss 1.6997009999999995 lambda= 0.0\n",
      "Total PID Loss 5.67276099999999 lambda= 0.0\n",
      "Total PID Loss 2.9052810000000013 lambda= 0.0\n",
      "Total PID Loss 1.726609 lambda= 0.0\n",
      "Total PID Loss 1.8763810000000007 lambda= 0.0\n",
      "Total PID Loss 16.430081 lambda= 0.0\n",
      "Total PID Loss 3.5242760000000013 lambda= 0.0\n",
      "Total PID Loss 1.6912410000000002 lambda= 0.0\n",
      "Total PID Loss 1.6938559999999998 lambda= 0.0\n",
      "Total PID Loss 3.6091690000000005 lambda= 0.0\n",
      "Total PID Loss 3.9194250000000013 lambda= 0.0\n",
      "Total PID Loss 15.730616000000005 lambda= 0.0\n",
      "Total PID Loss 3.8716239999999966 lambda= 0.0\n",
      "Total PID Loss 1.7430209999999993 lambda= 0.0\n",
      "Total PID Loss 1.7536410000000002 lambda= 0.0\n",
      "Total PID Loss 70.65156900000002 lambda= 0.0\n",
      "Total PID Loss 1.6873239999999998 lambda= 0.0\n",
      "Total PID Loss 1.6868960000000002 lambda= 0.0\n",
      "Total PID Loss 1.677956 lambda= 0.0\n",
      "Total PID Loss 3.6697009999999963 lambda= 0.0\n",
      "Total PID Loss 61.989676 lambda= 0.0\n",
      "Total PID Loss 2.7094000000000014 lambda= 0.0\n",
      "Total PID Loss 5.938861000000007 lambda= 0.0\n",
      "Total PID Loss 2.0763839999999987 lambda= 0.0\n",
      "Total PID Loss 2.291221000000001 lambda= 0.0\n",
      "Total PID Loss 1.8163409999999995 lambda= 0.0\n",
      "Total PID Loss 1.7766289999999998 lambda= 0.0\n",
      "Total PID Loss 1.6892760000000002 lambda= 0.0\n",
      "Total PID Loss 1.7263840000000001 lambda= 0.0\n",
      "Total PID Loss 1.675661 lambda= 0.0\n",
      "Total PID Loss 1.6856959999999996 lambda= 0.0\n",
      "Total PID Loss 1.676401 lambda= 0.0\n",
      "Total PID Loss 1.666921 lambda= 0.0\n",
      "Total PID Loss 1.668036 lambda= 0.0\n",
      "Total PID Loss 1.705725 lambda= 0.0\n",
      "Total PID Loss 1.6724959999999998 lambda= 0.0\n",
      "Total PID Loss 1.6668439999999998 lambda= 0.0\n",
      "Total PID Loss 1.668625 lambda= 0.0\n",
      "Total PID Loss 1.6899250000000001 lambda= 0.0\n",
      "Total PID Loss 1.669344 lambda= 0.0\n",
      "Total PID Loss 1.664625 lambda= 0.0\n",
      "Total PID Loss 1.6647359999999998 lambda= 0.0\n",
      "Total PID Loss 1.6586889999999999 lambda= 0.0\n",
      "Total PID Loss 1.652049 lambda= 0.0\n",
      "Total PID Loss 1.6649249999999998 lambda= 0.0\n",
      "Total PID Loss 1.655224 lambda= 0.0\n",
      "Total PID Loss 1.6497609999999996 lambda= 0.0\n",
      "Total PID Loss 1.6417159999999997 lambda= 0.0\n",
      "Total PID Loss 1.643889 lambda= 0.0\n",
      "Total PID Loss 1.6300999999999999 lambda= 0.0\n",
      "Total PID Loss 1.614064 lambda= 0.0\n",
      "Total PID Loss 1.6204 lambda= 0.0\n",
      "Total PID Loss 1.6057 lambda= 0.0\n",
      "Total PID Loss 1.5824889999999998 lambda= 0.0\n",
      "Total PID Loss 1.5829250000000001 lambda= 0.0\n",
      "Total PID Loss 1.570036 lambda= 0.0\n",
      "Total PID Loss 1.5570160000000002 lambda= 0.0\n",
      "Total PID Loss 1.541725 lambda= 0.0\n",
      "Total PID Loss 1.5217000000000003 lambda= 0.0\n",
      "Total PID Loss 1.522656 lambda= 0.0\n",
      "Total PID Loss 1.545841 lambda= 0.0\n",
      "Total PID Loss 1.6497840000000006 lambda= 0.0\n",
      "Total PID Loss 1.5429439999999999 lambda= 0.0\n",
      "Total PID Loss 1.5170840000000003 lambda= 0.0\n",
      "Total PID Loss 1.5440250000000002 lambda= 0.0\n",
      "Total PID Loss 1.5239250000000002 lambda= 0.0\n",
      "Total PID Loss 1.5263250000000006 lambda= 0.0\n",
      "Total PID Loss 1.5134089999999996 lambda= 0.0\n",
      "Total PID Loss 1.5755239999999986 lambda= 0.0\n",
      "Total PID Loss 1.5129160000000001 lambda= 0.0\n",
      "Total PID Loss 1.5044250000000001 lambda= 0.0\n",
      "Total PID Loss 1.4974249999999998 lambda= 0.0\n",
      "Total PID Loss 1.5022640000000005 lambda= 0.0\n",
      "Total PID Loss 1.498336 lambda= 0.0\n",
      "Total PID Loss 1.495225 lambda= 0.0\n",
      "Total PID Loss 1.500309 lambda= 0.0\n",
      "Total PID Loss 1.4884410000000003 lambda= 0.0\n",
      "Total PID Loss 1.5005490000000004 lambda= 0.0\n",
      "Total PID Loss 1.4984000000000002 lambda= 0.0\n",
      "Total PID Loss 1.493229 lambda= 0.0\n",
      "Total PID Loss 1.4855440000000002 lambda= 0.0\n",
      "Total PID Loss 1.4844409999999997 lambda= 0.0\n",
      "Total PID Loss 1.4782039999999999 lambda= 0.0\n",
      "Total PID Loss 1.472269 lambda= 0.0\n",
      "Total PID Loss 1.4853810000000007 lambda= 0.0\n",
      "Total PID Loss 1.5111040000000004 lambda= 0.0\n",
      "Total PID Loss 1.4828810000000001 lambda= 0.0\n",
      "Total PID Loss 1.4714810000000003 lambda= 0.0\n",
      "Total PID Loss 1.4675 lambda= 0.0\n",
      "Total PID Loss 1.484896 lambda= 0.0\n",
      "Total PID Loss 1.4774 lambda= 0.0\n",
      "Total PID Loss 1.480081 lambda= 0.0\n",
      "Total PID Loss 1.469024 lambda= 0.0\n",
      "Total PID Loss 1.470076 lambda= 0.0\n",
      "Total PID Loss 1.463796 lambda= 0.0\n",
      "Total PID Loss 1.4685000000000001 lambda= 0.0\n",
      "Total PID Loss 1.461916 lambda= 0.0\n",
      "Total PID Loss 1.4621760000000004 lambda= 0.0\n",
      "Total PID Loss 1.463556 lambda= 0.0\n",
      "Total PID Loss 1.465349 lambda= 0.0\n",
      "Total PID Loss 1.4637210000000003 lambda= 0.0\n",
      "Total PID Loss 1.4621359999999999 lambda= 0.0\n",
      "Total PID Loss 1.461301 lambda= 0.0\n",
      "Total PID Loss 1.463741 lambda= 0.0\n",
      "Total PID Loss 1.4733409999999998 lambda= 0.0\n",
      "Total PID Loss 1.460525 lambda= 0.0\n",
      "Total PID Loss 1.461064 lambda= 0.0\n",
      "Total PID Loss 1.462741 lambda= 0.0\n",
      "Total PID Loss 1.460796 lambda= 0.0\n",
      "Total PID Loss 1.4609249999999998 lambda= 0.0\n",
      "Total PID Loss 1.4619 lambda= 0.0\n",
      "Total PID Loss 1.460456 lambda= 0.0\n",
      "Total PID Loss 1.461921 lambda= 0.0\n",
      "Total PID Loss 1.4603810000000002 lambda= 0.0\n",
      "Total PID Loss 1.461916 lambda= 0.0\n",
      "Total PID Loss 1.4603249999999999 lambda= 0.0\n",
      "Total PID Loss 1.461109 lambda= 0.0\n",
      "Total PID Loss 1.4603840000000001 lambda= 0.0\n",
      "Total PID Loss 1.4608640000000002 lambda= 0.0\n",
      "Total PID Loss 1.4602959999999998 lambda= 0.0\n",
      "Total PID Loss 1.460425 lambda= 0.0\n",
      "Total PID Loss 1.460344 lambda= 0.0\n",
      "Total PID Loss 1.4607039999999998 lambda= 0.0\n",
      "Total PID Loss 1.460284 lambda= 0.0\n",
      "Total PID Loss 1.4602840000000001 lambda= 0.0\n",
      "Total PID Loss 1.460389 lambda= 0.0\n",
      "Total PID Loss 1.4602890000000002 lambda= 0.0\n",
      "Total PID Loss 1.4604959999999998 lambda= 0.0\n",
      "Total PID Loss 1.460229 lambda= 0.0\n",
      "Total PID Loss 1.4604 lambda= 0.0\n",
      "Total PID Loss 1.460324 lambda= 0.0\n",
      "Total PID Loss 1.460284 lambda= 0.0\n",
      "Total PID Loss 1.4603249999999999 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.460261 lambda= 0.0\n",
      "Total PID Loss 1.4602890000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.460229 lambda= 0.0\n",
      "Total PID Loss 1.4602000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4602410000000001 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n",
      "Total PID Loss 1.4603000000000002 lambda= 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 2.1102250000000002 lambda= 0.125\n",
      "Total PID Loss 2.086566 lambda= 0.125\n",
      "Total PID Loss 2.1102625 lambda= 0.125\n",
      "Total PID Loss 2.5930499999999976 lambda= 0.125\n",
      "Total PID Loss 2.110286 lambda= 0.125\n",
      "Total PID Loss 2.543499999999999 lambda= 0.125\n",
      "Total PID Loss 2.2119840000000006 lambda= 0.125\n",
      "Total PID Loss 2.2273640000000006 lambda= 0.125\n",
      "Total PID Loss 2.129059 lambda= 0.125\n",
      "Total PID Loss 2.1361190000000008 lambda= 0.125\n",
      "Total PID Loss 2.1091735000000003 lambda= 0.125\n",
      "Total PID Loss 2.097291 lambda= 0.125\n",
      "Total PID Loss 2.095199 lambda= 0.125\n",
      "Total PID Loss 2.096574 lambda= 0.125\n",
      "Total PID Loss 2.0756765 lambda= 0.125\n",
      "Total PID Loss 2.059761 lambda= 0.125\n",
      "Total PID Loss 2.0701035 lambda= 0.125\n",
      "Total PID Loss 2.065801 lambda= 0.125\n",
      "Total PID Loss 2.047675 lambda= 0.125\n",
      "Total PID Loss 2.0333785000000004 lambda= 0.125\n",
      "Total PID Loss 2.025866 lambda= 0.125\n",
      "Total PID Loss 2.0060865 lambda= 0.125\n",
      "Total PID Loss 2.0268625 lambda= 0.125\n",
      "Total PID Loss 2.0075874999999996 lambda= 0.125\n",
      "Total PID Loss 2.0477959999999995 lambda= 0.125\n",
      "Total PID Loss 2.0189939999999997 lambda= 0.125\n",
      "Total PID Loss 2.0158564999999995 lambda= 0.125\n",
      "Total PID Loss 2.0076634999999996 lambda= 0.125\n",
      "Total PID Loss 1.9927934999999994 lambda= 0.125\n",
      "Total PID Loss 1.9856189999999998 lambda= 0.125\n",
      "Total PID Loss 1.9962659999999999 lambda= 0.125\n",
      "Total PID Loss 2.0183735 lambda= 0.125\n",
      "Total PID Loss 1.9963935000000004 lambda= 0.125\n",
      "Total PID Loss 1.9873485 lambda= 0.125\n",
      "Total PID Loss 1.9813735000000003 lambda= 0.125\n",
      "Total PID Loss 1.9887999999999995 lambda= 0.125\n",
      "Total PID Loss 1.988216 lambda= 0.125\n",
      "Total PID Loss 1.979625 lambda= 0.125\n",
      "Total PID Loss 1.9955790000000002 lambda= 0.125\n",
      "Total PID Loss 1.9941860000000005 lambda= 0.125\n",
      "Total PID Loss 1.9821875000000002 lambda= 0.125\n",
      "Total PID Loss 1.985856 lambda= 0.125\n",
      "Total PID Loss 1.981191 lambda= 0.125\n",
      "Total PID Loss 1.978589 lambda= 0.125\n",
      "Total PID Loss 1.9827874999999997 lambda= 0.125\n",
      "Total PID Loss 1.9949625000000002 lambda= 0.125\n",
      "Total PID Loss 1.9791159999999999 lambda= 0.125\n",
      "Total PID Loss 1.9781914999999999 lambda= 0.125\n",
      "Total PID Loss 1.9789634999999999 lambda= 0.125\n",
      "Total PID Loss 1.9773999999999998 lambda= 0.125\n",
      "Total PID Loss 1.9784915 lambda= 0.125\n",
      "Total PID Loss 1.9775809999999998 lambda= 0.125\n",
      "Total PID Loss 1.9812835 lambda= 0.125\n",
      "Total PID Loss 1.9777125 lambda= 0.125\n",
      "Total PID Loss 1.9780250000000001 lambda= 0.125\n",
      "Total PID Loss 1.9795 lambda= 0.125\n",
      "Total PID Loss 1.977481 lambda= 0.125\n",
      "Total PID Loss 1.9780510000000002 lambda= 0.125\n",
      "Total PID Loss 1.9775565 lambda= 0.125\n",
      "Total PID Loss 1.9779315 lambda= 0.125\n",
      "Total PID Loss 1.9774874999999998 lambda= 0.125\n",
      "Total PID Loss 1.9776064999999998 lambda= 0.125\n",
      "Total PID Loss 1.9774185 lambda= 0.125\n",
      "Total PID Loss 1.9775939999999999 lambda= 0.125\n",
      "Total PID Loss 1.9773740000000002 lambda= 0.125\n",
      "Total PID Loss 1.977529 lambda= 0.125\n",
      "Total PID Loss 1.977351 lambda= 0.125\n",
      "Total PID Loss 1.9776015 lambda= 0.125\n",
      "Total PID Loss 1.977379 lambda= 0.125\n",
      "Total PID Loss 1.9774485 lambda= 0.125\n",
      "Total PID Loss 1.9773749999999999 lambda= 0.125\n",
      "Total PID Loss 1.9775 lambda= 0.125\n",
      "Total PID Loss 1.9773415 lambda= 0.125\n",
      "Total PID Loss 1.9774625000000001 lambda= 0.125\n",
      "Total PID Loss 1.977351 lambda= 0.125\n",
      "Total PID Loss 1.9774 lambda= 0.125\n",
      "Total PID Loss 1.977366 lambda= 0.125\n",
      "Total PID Loss 1.9774215000000002 lambda= 0.125\n",
      "Total PID Loss 1.9774285 lambda= 0.125\n",
      "Total PID Loss 1.9773635 lambda= 0.125\n",
      "Total PID Loss 1.9773635 lambda= 0.125\n",
      "Total PID Loss 1.9773965000000002 lambda= 0.125\n",
      "Total PID Loss 1.9774159999999998 lambda= 0.125\n",
      "Total PID Loss 1.9773635 lambda= 0.125\n",
      "Total PID Loss 1.9773885 lambda= 0.125\n",
      "Total PID Loss 1.977325 lambda= 0.125\n",
      "Total PID Loss 1.9773465 lambda= 0.125\n",
      "Total PID Loss 1.977354 lambda= 0.125\n",
      "Total PID Loss 1.9774384999999999 lambda= 0.125\n",
      "Total PID Loss 1.977426 lambda= 0.125\n",
      "Total PID Loss 1.9773260000000001 lambda= 0.125\n",
      "Total PID Loss 1.977351 lambda= 0.125\n",
      "Total PID Loss 1.9773885 lambda= 0.125\n",
      "Total PID Loss 1.9773635 lambda= 0.125\n",
      "Total PID Loss 1.9773635 lambda= 0.125\n",
      "Total PID Loss 1.9773885 lambda= 0.125\n",
      "Total PID Loss 1.97735 lambda= 0.125\n",
      "Total PID Loss 1.9773635 lambda= 0.125\n",
      "Total PID Loss 1.9774124999999998 lambda= 0.125\n",
      "Total PID Loss 1.977425 lambda= 0.125\n",
      "Total PID Loss 1.9773625 lambda= 0.125\n",
      "Total PID Loss 1.9773625 lambda= 0.125\n",
      "Total PID Loss 1.9773375 lambda= 0.125\n",
      "Total PID Loss 1.977325 lambda= 0.125\n",
      "Total PID Loss 1.9773874999999999 lambda= 0.125\n",
      "Total PID Loss 1.9773749999999999 lambda= 0.125\n",
      "Total PID Loss 1.977325 lambda= 0.125\n",
      "Total PID Loss 1.9773249999999998 lambda= 0.125\n",
      "Total PID Loss 1.9773375 lambda= 0.125\n",
      "Total PID Loss 1.97735 lambda= 0.125\n",
      "Total PID Loss 1.97735 lambda= 0.125\n",
      "Total PID Loss 1.9773874999999999 lambda= 0.125\n",
      "Total PID Loss 1.977325 lambda= 0.125\n",
      "Total PID Loss 1.977325 lambda= 0.125\n",
      "Total PID Loss 1.9773749999999999 lambda= 0.125\n",
      "Total PID Loss 1.9773375 lambda= 0.125\n",
      "Total PID Loss 2.3858249999999996 lambda= 0.25\n",
      "Total PID Loss 2.3717440000000005 lambda= 0.25\n",
      "Total PID Loss 2.385875 lambda= 0.25\n",
      "Total PID Loss 2.737766 lambda= 0.25\n",
      "Total PID Loss 2.3858499999999996 lambda= 0.25\n",
      "Total PID Loss 2.608766000000001 lambda= 0.25\n",
      "Total PID Loss 2.4265250000000003 lambda= 0.25\n",
      "Total PID Loss 2.480314 lambda= 0.25\n",
      "Total PID Loss 2.3858439999999996 lambda= 0.25\n",
      "Total PID Loss 2.368619 lambda= 0.25\n",
      "Total PID Loss 2.360939 lambda= 0.25\n",
      "Total PID Loss 2.357424 lambda= 0.25\n",
      "Total PID Loss 2.3459390000000004 lambda= 0.25\n",
      "Total PID Loss 2.372845999999999 lambda= 0.25\n",
      "Total PID Loss 2.3494910000000004 lambda= 0.25\n",
      "Total PID Loss 2.349386 lambda= 0.25\n",
      "Total PID Loss 2.3357710000000003 lambda= 0.25\n",
      "Total PID Loss 2.3347939999999996 lambda= 0.25\n",
      "Total PID Loss 2.320639 lambda= 0.25\n",
      "Total PID Loss 2.3190999999999997 lambda= 0.25\n",
      "Total PID Loss 2.3637359999999994 lambda= 0.25\n",
      "Total PID Loss 2.3322190000000003 lambda= 0.25\n",
      "Total PID Loss 2.318375 lambda= 0.25\n",
      "Total PID Loss 2.3473589999999995 lambda= 0.25\n",
      "Total PID Loss 2.329374 lambda= 0.25\n",
      "Total PID Loss 2.3773749999999993 lambda= 0.25\n",
      "Total PID Loss 2.318536 lambda= 0.25\n",
      "Total PID Loss 2.346435999999999 lambda= 0.25\n",
      "Total PID Loss 2.3202109999999996 lambda= 0.25\n",
      "Total PID Loss 2.33185 lambda= 0.25\n",
      "Total PID Loss 2.318314 lambda= 0.25\n",
      "Total PID Loss 2.3181460000000005 lambda= 0.25\n",
      "Total PID Loss 2.3281660000000004 lambda= 0.25\n",
      "Total PID Loss 2.314191 lambda= 0.25\n",
      "Total PID Loss 2.315016 lambda= 0.25\n",
      "Total PID Loss 2.3373340000000002 lambda= 0.25\n",
      "Total PID Loss 2.315086 lambda= 0.25\n",
      "Total PID Loss 2.313921 lambda= 0.25\n",
      "Total PID Loss 2.3144 lambda= 0.25\n",
      "Total PID Loss 2.314584 lambda= 0.25\n",
      "Total PID Loss 2.3198689999999997 lambda= 0.25\n",
      "Total PID Loss 2.31465 lambda= 0.25\n",
      "Total PID Loss 2.3142389999999997 lambda= 0.25\n",
      "Total PID Loss 2.3148 lambda= 0.25\n",
      "Total PID Loss 2.313819 lambda= 0.25\n",
      "Total PID Loss 2.316166 lambda= 0.25\n",
      "Total PID Loss 2.313796 lambda= 0.25\n",
      "Total PID Loss 2.314786 lambda= 0.25\n",
      "Total PID Loss 2.313775 lambda= 0.25\n",
      "Total PID Loss 2.31445 lambda= 0.25\n",
      "Total PID Loss 2.313791 lambda= 0.25\n",
      "Total PID Loss 2.313816 lambda= 0.25\n",
      "Total PID Loss 2.3139890000000003 lambda= 0.25\n",
      "Total PID Loss 2.3137109999999996 lambda= 0.25\n",
      "Total PID Loss 2.313774 lambda= 0.25\n",
      "Total PID Loss 2.3141909999999997 lambda= 0.25\n",
      "Total PID Loss 2.313609 lambda= 0.25\n",
      "Total PID Loss 2.3138750000000003 lambda= 0.25\n",
      "Total PID Loss 2.313684 lambda= 0.25\n",
      "Total PID Loss 2.313804 lambda= 0.25\n",
      "Total PID Loss 2.313666 lambda= 0.25\n",
      "Total PID Loss 2.313726 lambda= 0.25\n",
      "Total PID Loss 2.313701 lambda= 0.25\n",
      "Total PID Loss 2.3136590000000004 lambda= 0.25\n",
      "Total PID Loss 2.313625 lambda= 0.25\n",
      "Total PID Loss 2.313716 lambda= 0.25\n",
      "Total PID Loss 2.3136259999999997 lambda= 0.25\n",
      "Total PID Loss 2.313736 lambda= 0.25\n",
      "Total PID Loss 2.3136010000000002 lambda= 0.25\n",
      "Total PID Loss 2.313659 lambda= 0.25\n",
      "Total PID Loss 2.313654 lambda= 0.25\n",
      "Total PID Loss 2.313654 lambda= 0.25\n",
      "Total PID Loss 2.313626 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313625 lambda= 0.25\n",
      "Total PID Loss 2.313654 lambda= 0.25\n",
      "Total PID Loss 2.313701 lambda= 0.25\n",
      "Total PID Loss 2.3136010000000002 lambda= 0.25\n",
      "Total PID Loss 2.3136509999999997 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313651 lambda= 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 2.313651 lambda= 0.25\n",
      "Total PID Loss 2.313701 lambda= 0.25\n",
      "Total PID Loss 2.3136 lambda= 0.25\n",
      "Total PID Loss 2.313651 lambda= 0.25\n",
      "Total PID Loss 2.313626 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313626 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313651 lambda= 0.25\n",
      "Total PID Loss 2.313626 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313701 lambda= 0.25\n",
      "Total PID Loss 2.313651 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313701 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313651 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.313676 lambda= 0.25\n",
      "Total PID Loss 2.5865874999999994 lambda= 0.375\n",
      "Total PID Loss 2.6125940000000005 lambda= 0.375\n",
      "Total PID Loss 2.5866249999999997 lambda= 0.375\n",
      "Total PID Loss 2.808498500000001 lambda= 0.375\n",
      "Total PID Loss 2.5865874999999994 lambda= 0.375\n",
      "Total PID Loss 2.6541264999999994 lambda= 0.375\n",
      "Total PID Loss 2.5866240000000005 lambda= 0.375\n",
      "Total PID Loss 2.6734624999999994 lambda= 0.375\n",
      "Total PID Loss 2.581994 lambda= 0.375\n",
      "Total PID Loss 2.5721415 lambda= 0.375\n",
      "Total PID Loss 2.5661 lambda= 0.375\n",
      "Total PID Loss 2.6133190000000006 lambda= 0.375\n",
      "Total PID Loss 2.5768874999999998 lambda= 0.375\n",
      "Total PID Loss 2.5639885 lambda= 0.375\n",
      "Total PID Loss 2.555421 lambda= 0.375\n",
      "Total PID Loss 2.552061 lambda= 0.375\n",
      "Total PID Loss 2.5452109999999997 lambda= 0.375\n",
      "Total PID Loss 2.5536114999999997 lambda= 0.375\n",
      "Total PID Loss 2.5429565 lambda= 0.375\n",
      "Total PID Loss 2.5727125000000006 lambda= 0.375\n",
      "Total PID Loss 2.5460489999999996 lambda= 0.375\n",
      "Total PID Loss 2.5480909999999994 lambda= 0.375\n",
      "Total PID Loss 2.6110390000000008 lambda= 0.375\n",
      "Total PID Loss 2.54035 lambda= 0.375\n",
      "Total PID Loss 2.5527865 lambda= 0.375\n",
      "Total PID Loss 2.5416125000000003 lambda= 0.375\n",
      "Total PID Loss 2.5441624999999997 lambda= 0.375\n",
      "Total PID Loss 2.537826 lambda= 0.375\n",
      "Total PID Loss 2.538109 lambda= 0.375\n",
      "Total PID Loss 2.5438125 lambda= 0.375\n",
      "Total PID Loss 2.5397165 lambda= 0.375\n",
      "Total PID Loss 2.537769 lambda= 0.375\n",
      "Total PID Loss 2.540475 lambda= 0.375\n",
      "Total PID Loss 2.5419389999999997 lambda= 0.375\n",
      "Total PID Loss 2.5386560000000005 lambda= 0.375\n",
      "Total PID Loss 2.5433375 lambda= 0.375\n",
      "Total PID Loss 2.5383135 lambda= 0.375\n",
      "Total PID Loss 2.5396834999999998 lambda= 0.375\n",
      "Total PID Loss 2.5381865 lambda= 0.375\n",
      "Total PID Loss 2.5407789999999997 lambda= 0.375\n",
      "Total PID Loss 2.537719 lambda= 0.375\n",
      "Total PID Loss 2.537624 lambda= 0.375\n",
      "Total PID Loss 2.5381985 lambda= 0.375\n",
      "Total PID Loss 2.5377834999999997 lambda= 0.375\n",
      "Total PID Loss 2.5381365 lambda= 0.375\n",
      "Total PID Loss 2.537625 lambda= 0.375\n",
      "Total PID Loss 2.5380115 lambda= 0.375\n",
      "Total PID Loss 2.537611 lambda= 0.375\n",
      "Total PID Loss 2.537911 lambda= 0.375\n",
      "Total PID Loss 2.5375734999999997 lambda= 0.375\n",
      "Total PID Loss 2.5379625 lambda= 0.375\n",
      "Total PID Loss 2.5375750000000004 lambda= 0.375\n",
      "Total PID Loss 2.537675 lambda= 0.375\n",
      "Total PID Loss 2.5374885000000003 lambda= 0.375\n",
      "Total PID Loss 2.5376875 lambda= 0.375\n",
      "Total PID Loss 2.5375715000000003 lambda= 0.375\n",
      "Total PID Loss 2.5376015 lambda= 0.375\n",
      "Total PID Loss 2.5375535 lambda= 0.375\n",
      "Total PID Loss 2.537669 lambda= 0.375\n",
      "Total PID Loss 2.537576 lambda= 0.375\n",
      "Total PID Loss 2.5375415 lambda= 0.375\n",
      "Total PID Loss 2.5374790000000003 lambda= 0.375\n",
      "Total PID Loss 2.5375465000000004 lambda= 0.375\n",
      "Total PID Loss 2.5374915000000002 lambda= 0.375\n",
      "Total PID Loss 2.537554 lambda= 0.375\n",
      "Total PID Loss 2.5375415 lambda= 0.375\n",
      "Total PID Loss 2.5375509999999997 lambda= 0.375\n",
      "Total PID Loss 2.5375135 lambda= 0.375\n",
      "Total PID Loss 2.537529 lambda= 0.375\n",
      "Total PID Loss 2.5375385 lambda= 0.375\n",
      "Total PID Loss 2.5375259999999997 lambda= 0.375\n",
      "Total PID Loss 2.5375125 lambda= 0.375\n",
      "Total PID Loss 2.5374915 lambda= 0.375\n",
      "Total PID Loss 2.537529 lambda= 0.375\n",
      "Total PID Loss 2.5374999999999996 lambda= 0.375\n",
      "Total PID Loss 2.5375625 lambda= 0.375\n",
      "Total PID Loss 2.5374885000000003 lambda= 0.375\n",
      "Total PID Loss 2.5375415 lambda= 0.375\n",
      "Total PID Loss 2.5375625 lambda= 0.375\n",
      "Total PID Loss 2.5375385 lambda= 0.375\n",
      "Total PID Loss 2.5375165 lambda= 0.375\n",
      "Total PID Loss 2.5375385 lambda= 0.375\n",
      "Total PID Loss 2.537526 lambda= 0.375\n",
      "Total PID Loss 2.5375415 lambda= 0.375\n",
      "Total PID Loss 2.537551 lambda= 0.375\n",
      "Total PID Loss 2.5375165 lambda= 0.375\n",
      "Total PID Loss 2.5375260000000006 lambda= 0.375\n",
      "Total PID Loss 2.5375165 lambda= 0.375\n",
      "Total PID Loss 2.537551 lambda= 0.375\n",
      "Total PID Loss 2.537529 lambda= 0.375\n",
      "Total PID Loss 2.5374915 lambda= 0.375\n",
      "Total PID Loss 2.5375039999999998 lambda= 0.375\n",
      "Total PID Loss 2.5375414999999997 lambda= 0.375\n",
      "Total PID Loss 2.5375414999999997 lambda= 0.375\n",
      "Total PID Loss 2.537504 lambda= 0.375\n",
      "Total PID Loss 2.5375414999999997 lambda= 0.375\n",
      "Total PID Loss 2.537529 lambda= 0.375\n",
      "Total PID Loss 2.5374665 lambda= 0.375\n",
      "Total PID Loss 2.716979 lambda= 0.5\n",
      "Total PID Loss 2.8008249999999992 lambda= 0.5\n",
      "Total PID Loss 2.717029 lambda= 0.5\n",
      "Total PID Loss 2.8410860000000007 lambda= 0.5\n",
      "Total PID Loss 2.717029 lambda= 0.5\n",
      "Total PID Loss 2.709404 lambda= 0.5\n",
      "Total PID Loss 2.768796000000001 lambda= 0.5\n",
      "Total PID Loss 2.8771750000000003 lambda= 0.5\n",
      "Total PID Loss 2.7232749999999997 lambda= 0.5\n",
      "Total PID Loss 2.7631499999999996 lambda= 0.5\n",
      "Total PID Loss 2.709276 lambda= 0.5\n",
      "Total PID Loss 2.700906 lambda= 0.5\n",
      "Total PID Loss 2.695279 lambda= 0.5\n",
      "Total PID Loss 2.6928 lambda= 0.5\n",
      "Total PID Loss 2.686141 lambda= 0.5\n",
      "Total PID Loss 2.683934 lambda= 0.5\n",
      "Total PID Loss 2.687036 lambda= 0.5\n",
      "Total PID Loss 2.6868 lambda= 0.5\n",
      "Total PID Loss 2.684836 lambda= 0.5\n",
      "Total PID Loss 2.691149 lambda= 0.5\n",
      "Total PID Loss 2.682071 lambda= 0.5\n",
      "Total PID Loss 2.69515 lambda= 0.5\n",
      "Total PID Loss 2.681574 lambda= 0.5\n",
      "Total PID Loss 2.6867110000000007 lambda= 0.5\n",
      "Total PID Loss 2.682994 lambda= 0.5\n",
      "Total PID Loss 2.685444 lambda= 0.5\n",
      "Total PID Loss 2.682359 lambda= 0.5\n",
      "Total PID Loss 2.6819509999999998 lambda= 0.5\n",
      "Total PID Loss 2.6849290000000003 lambda= 0.5\n",
      "Total PID Loss 2.681514 lambda= 0.5\n",
      "Total PID Loss 2.682021 lambda= 0.5\n",
      "Total PID Loss 2.6825859999999997 lambda= 0.5\n",
      "Total PID Loss 2.681219 lambda= 0.5\n",
      "Total PID Loss 2.682054 lambda= 0.5\n",
      "Total PID Loss 2.681216 lambda= 0.5\n",
      "Total PID Loss 2.682146 lambda= 0.5\n",
      "Total PID Loss 2.6811999999999996 lambda= 0.5\n",
      "Total PID Loss 2.682271 lambda= 0.5\n",
      "Total PID Loss 2.6811239999999996 lambda= 0.5\n",
      "Total PID Loss 2.6824239999999997 lambda= 0.5\n",
      "Total PID Loss 2.681029 lambda= 0.5\n",
      "Total PID Loss 2.6812060000000004 lambda= 0.5\n",
      "Total PID Loss 2.681124 lambda= 0.5\n",
      "Total PID Loss 2.681229 lambda= 0.5\n",
      "Total PID Loss 2.6810609999999997 lambda= 0.5\n",
      "Total PID Loss 2.681619 lambda= 0.5\n",
      "Total PID Loss 2.6809890000000003 lambda= 0.5\n",
      "Total PID Loss 2.681081 lambda= 0.5\n",
      "Total PID Loss 2.680974 lambda= 0.5\n",
      "Total PID Loss 2.6812060000000004 lambda= 0.5\n",
      "Total PID Loss 2.6811610000000003 lambda= 0.5\n",
      "Total PID Loss 2.681025 lambda= 0.5\n",
      "Total PID Loss 2.681111 lambda= 0.5\n",
      "Total PID Loss 2.681011 lambda= 0.5\n",
      "Total PID Loss 2.681114 lambda= 0.5\n",
      "Total PID Loss 2.6809839999999996 lambda= 0.5\n",
      "Total PID Loss 2.681029 lambda= 0.5\n",
      "Total PID Loss 2.6809890000000003 lambda= 0.5\n",
      "Total PID Loss 2.681024 lambda= 0.5\n",
      "Total PID Loss 2.680961 lambda= 0.5\n",
      "Total PID Loss 2.680991 lambda= 0.5\n",
      "Total PID Loss 2.680974 lambda= 0.5\n",
      "Total PID Loss 2.680991 lambda= 0.5\n",
      "Total PID Loss 2.680974 lambda= 0.5\n",
      "Total PID Loss 2.6809959999999995 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.680974 lambda= 0.5\n",
      "Total PID Loss 2.681024 lambda= 0.5\n",
      "Total PID Loss 2.680961 lambda= 0.5\n",
      "Total PID Loss 2.6809410000000002 lambda= 0.5\n",
      "Total PID Loss 2.68095 lambda= 0.5\n",
      "Total PID Loss 2.680941 lambda= 0.5\n",
      "Total PID Loss 2.6809839999999996 lambda= 0.5\n",
      "Total PID Loss 2.680991 lambda= 0.5\n",
      "Total PID Loss 2.681011 lambda= 0.5\n",
      "Total PID Loss 2.680941 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.68095 lambda= 0.5\n",
      "Total PID Loss 2.68095 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.6809410000000002 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.680941 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.680941 lambda= 0.5\n",
      "Total PID Loss 2.68105 lambda= 0.5\n",
      "Total PID Loss 2.681 lambda= 0.5\n",
      "Total PID Loss 2.6809410000000002 lambda= 0.5\n",
      "Total PID Loss 2.680991 lambda= 0.5\n",
      "Total PID Loss 2.7918909999999997 lambda= 0.625\n",
      "Total PID Loss 2.944489 lambda= 0.625\n",
      "Total PID Loss 2.7918909999999997 lambda= 0.625\n",
      "Total PID Loss 2.8593765 lambda= 0.625\n",
      "Total PID Loss 2.7918909999999997 lambda= 0.625\n",
      "Total PID Loss 2.9094665 lambda= 0.625\n",
      "Total PID Loss 2.8263749999999996 lambda= 0.625\n",
      "Total PID Loss 2.8498589999999995 lambda= 0.625\n",
      "Total PID Loss 2.8109015000000004 lambda= 0.625\n",
      "Total PID Loss 2.7798235 lambda= 0.625\n",
      "Total PID Loss 2.7997875 lambda= 0.625\n",
      "Total PID Loss 2.8160160000000003 lambda= 0.625\n",
      "Total PID Loss 2.792744 lambda= 0.625\n",
      "Total PID Loss 2.7953260000000006 lambda= 0.625\n",
      "Total PID Loss 2.7884965 lambda= 0.625\n",
      "Total PID Loss 2.7815715 lambda= 0.625\n",
      "Total PID Loss 2.7776810000000003 lambda= 0.625\n",
      "Total PID Loss 2.7737735 lambda= 0.625\n",
      "Total PID Loss 2.7729985 lambda= 0.625\n",
      "Total PID Loss 2.777526 lambda= 0.625\n",
      "Total PID Loss 2.7845625000000007 lambda= 0.625\n",
      "Total PID Loss 2.7770034999999997 lambda= 0.625\n",
      "Total PID Loss 2.781545999999999 lambda= 0.625\n",
      "Total PID Loss 2.7765414999999996 lambda= 0.625\n",
      "Total PID Loss 2.7739914999999997 lambda= 0.625\n",
      "Total PID Loss 2.7705764999999998 lambda= 0.625\n",
      "Total PID Loss 2.768104 lambda= 0.625\n",
      "Total PID Loss 2.7683375 lambda= 0.625\n",
      "Total PID Loss 2.7733435 lambda= 0.625\n",
      "Total PID Loss 2.7669509999999997 lambda= 0.625\n",
      "Total PID Loss 2.7652124999999996 lambda= 0.625\n",
      "Total PID Loss 2.7699065000000003 lambda= 0.625\n",
      "Total PID Loss 2.764349 lambda= 0.625\n",
      "Total PID Loss 2.765129 lambda= 0.625\n",
      "Total PID Loss 2.7686735 lambda= 0.625\n",
      "Total PID Loss 2.7664235 lambda= 0.625\n",
      "Total PID Loss 2.764025 lambda= 0.625\n",
      "Total PID Loss 2.764341 lambda= 0.625\n",
      "Total PID Loss 2.7645335 lambda= 0.625\n",
      "Total PID Loss 2.7649375000000003 lambda= 0.625\n",
      "Total PID Loss 2.7661875 lambda= 0.625\n",
      "Total PID Loss 2.7641335000000002 lambda= 0.625\n",
      "Total PID Loss 2.7655659999999997 lambda= 0.625\n",
      "Total PID Loss 2.7640785 lambda= 0.625\n",
      "Total PID Loss 2.7661490000000004 lambda= 0.625\n",
      "Total PID Loss 2.7639410000000004 lambda= 0.625\n",
      "Total PID Loss 2.764134 lambda= 0.625\n",
      "Total PID Loss 2.7639485 lambda= 0.625\n",
      "Total PID Loss 2.7640815 lambda= 0.625\n",
      "Total PID Loss 2.7639565 lambda= 0.625\n",
      "Total PID Loss 2.764151 lambda= 0.625\n",
      "Total PID Loss 2.7639125 lambda= 0.625\n",
      "Total PID Loss 2.7641885000000004 lambda= 0.625\n",
      "Total PID Loss 2.76395 lambda= 0.625\n",
      "Total PID Loss 2.7639765 lambda= 0.625\n",
      "Total PID Loss 2.7638834999999995 lambda= 0.625\n",
      "Total PID Loss 2.7639465 lambda= 0.625\n",
      "Total PID Loss 2.7639084999999994 lambda= 0.625\n",
      "Total PID Loss 2.7639265 lambda= 0.625\n",
      "Total PID Loss 2.764176 lambda= 0.625\n",
      "Total PID Loss 2.763956 lambda= 0.625\n",
      "Total PID Loss 2.763896 lambda= 0.625\n",
      "Total PID Loss 2.7638815 lambda= 0.625\n",
      "Total PID Loss 2.763846 lambda= 0.625\n",
      "Total PID Loss 2.763899 lambda= 0.625\n",
      "Total PID Loss 2.7639765 lambda= 0.625\n",
      "Total PID Loss 2.7639 lambda= 0.625\n",
      "Total PID Loss 2.763921 lambda= 0.625\n",
      "Total PID Loss 2.7639315 lambda= 0.625\n",
      "Total PID Loss 2.7639065 lambda= 0.625\n",
      "Total PID Loss 2.763896 lambda= 0.625\n",
      "Total PID Loss 2.7638939999999996 lambda= 0.625\n",
      "Total PID Loss 2.7639065 lambda= 0.625\n",
      "Total PID Loss 2.7638565 lambda= 0.625\n",
      "Total PID Loss 2.763944 lambda= 0.625\n",
      "Total PID Loss 2.7639565 lambda= 0.625\n",
      "Total PID Loss 2.763869 lambda= 0.625\n",
      "Total PID Loss 2.7639584999999998 lambda= 0.625\n",
      "Total PID Loss 2.7639065 lambda= 0.625\n",
      "Total PID Loss 2.763869 lambda= 0.625\n",
      "Total PID Loss 2.763894 lambda= 0.625\n",
      "Total PID Loss 2.763871 lambda= 0.625\n",
      "Total PID Loss 2.76395 lambda= 0.625\n",
      "Total PID Loss 2.7638814999999997 lambda= 0.625\n",
      "Total PID Loss 2.7639085000000003 lambda= 0.625\n",
      "Total PID Loss 2.7639709999999997 lambda= 0.625\n",
      "Total PID Loss 2.7639460000000002 lambda= 0.625\n",
      "Total PID Loss 2.763946 lambda= 0.625\n",
      "Total PID Loss 2.7638585000000004 lambda= 0.625\n",
      "Total PID Loss 2.763921 lambda= 0.625\n",
      "Total PID Loss 2.7638585000000004 lambda= 0.625\n",
      "Total PID Loss 2.7639375 lambda= 0.625\n",
      "Total PID Loss 2.763896 lambda= 0.625\n",
      "Total PID Loss 2.7639375 lambda= 0.625\n",
      "Total PID Loss 2.763896 lambda= 0.625\n",
      "Total PID Loss 2.7639625 lambda= 0.625\n",
      "Total PID Loss 2.7639335 lambda= 0.625\n",
      "Total PID Loss 2.763871 lambda= 0.625\n",
      "Total PID Loss 2.763871 lambda= 0.625\n",
      "Total PID Loss 2.763921 lambda= 0.625\n",
      "Total PID Loss 2.763921 lambda= 0.625\n",
      "Total PID Loss 2.8208710000000004 lambda= 0.75\n",
      "Total PID Loss 3.045051 lambda= 0.75\n",
      "Total PID Loss 2.820946 lambda= 0.75\n",
      "Total PID Loss 2.8579499999999998 lambda= 0.75\n",
      "Total PID Loss 2.820946 lambda= 0.75\n",
      "Total PID Loss 3.0164940000000002 lambda= 0.75\n",
      "Total PID Loss 2.8756040000000005 lambda= 0.75\n",
      "Total PID Loss 2.879949 lambda= 0.75\n",
      "Total PID Loss 2.8388739999999997 lambda= 0.75\n",
      "Total PID Loss 2.829929 lambda= 0.75\n",
      "Total PID Loss 2.807894 lambda= 0.75\n",
      "Total PID Loss 2.8108190000000004 lambda= 0.75\n",
      "Total PID Loss 2.851190999999999 lambda= 0.75\n",
      "Total PID Loss 2.8180359999999998 lambda= 0.75\n",
      "Total PID Loss 2.81065 lambda= 0.75\n",
      "Total PID Loss 2.807064 lambda= 0.75\n",
      "Total PID Loss 2.803375 lambda= 0.75\n",
      "Total PID Loss 2.8022990000000005 lambda= 0.75\n",
      "Total PID Loss 2.8033609999999993 lambda= 0.75\n",
      "Total PID Loss 2.8025459999999995 lambda= 0.75\n",
      "Total PID Loss 2.8030559999999998 lambda= 0.75\n",
      "Total PID Loss 2.806071 lambda= 0.75\n",
      "Total PID Loss 2.8016509999999997 lambda= 0.75\n",
      "Total PID Loss 2.809024 lambda= 0.75\n",
      "Total PID Loss 2.801166 lambda= 0.75\n",
      "Total PID Loss 2.803116 lambda= 0.75\n",
      "Total PID Loss 2.8012189999999997 lambda= 0.75\n",
      "Total PID Loss 2.8042709999999995 lambda= 0.75\n",
      "Total PID Loss 2.801071 lambda= 0.75\n",
      "Total PID Loss 2.804275 lambda= 0.75\n",
      "Total PID Loss 2.801034 lambda= 0.75\n",
      "Total PID Loss 2.8018840000000003 lambda= 0.75\n",
      "Total PID Loss 2.800941 lambda= 0.75\n",
      "Total PID Loss 2.8015 lambda= 0.75\n",
      "Total PID Loss 2.800776 lambda= 0.75\n",
      "Total PID Loss 2.801631 lambda= 0.75\n",
      "Total PID Loss 2.800719 lambda= 0.75\n",
      "Total PID Loss 2.8012999999999995 lambda= 0.75\n",
      "Total PID Loss 2.8007 lambda= 0.75\n",
      "Total PID Loss 2.8013000000000003 lambda= 0.75\n",
      "Total PID Loss 2.800794 lambda= 0.75\n",
      "Total PID Loss 2.8008990000000002 lambda= 0.75\n",
      "Total PID Loss 2.800749 lambda= 0.75\n",
      "Total PID Loss 2.8008410000000006 lambda= 0.75\n",
      "Total PID Loss 2.800681 lambda= 0.75\n",
      "Total PID Loss 2.800925 lambda= 0.75\n",
      "Total PID Loss 2.800759 lambda= 0.75\n",
      "Total PID Loss 2.800746 lambda= 0.75\n",
      "Total PID Loss 2.8007310000000003 lambda= 0.75\n",
      "Total PID Loss 2.8007910000000003 lambda= 0.75\n",
      "Total PID Loss 2.800781 lambda= 0.75\n",
      "Total PID Loss 2.8007409999999995 lambda= 0.75\n",
      "Total PID Loss 2.8006960000000003 lambda= 0.75\n",
      "Total PID Loss 2.800756 lambda= 0.75\n",
      "Total PID Loss 2.80075 lambda= 0.75\n",
      "Total PID Loss 2.800714 lambda= 0.75\n",
      "Total PID Loss 2.8007109999999997 lambda= 0.75\n",
      "Total PID Loss 2.800719 lambda= 0.75\n",
      "Total PID Loss 2.800775 lambda= 0.75\n",
      "Total PID Loss 2.800725 lambda= 0.75\n",
      "Total PID Loss 2.800699 lambda= 0.75\n",
      "Total PID Loss 2.800714 lambda= 0.75\n",
      "Total PID Loss 2.800624 lambda= 0.75\n",
      "Total PID Loss 2.8007110000000006 lambda= 0.75\n",
      "Total PID Loss 2.8006610000000003 lambda= 0.75\n",
      "Total PID Loss 2.800656 lambda= 0.75\n",
      "Total PID Loss 2.8006640000000003 lambda= 0.75\n",
      "Total PID Loss 2.8007250000000004 lambda= 0.75\n",
      "Total PID Loss 2.8007139999999997 lambda= 0.75\n",
      "Total PID Loss 2.800639 lambda= 0.75\n",
      "Total PID Loss 2.800736 lambda= 0.75\n",
      "Total PID Loss 2.800724 lambda= 0.75\n",
      "Total PID Loss 2.800689 lambda= 0.75\n",
      "Total PID Loss 2.8007139999999997 lambda= 0.75\n",
      "Total PID Loss 2.8006889999999998 lambda= 0.75\n",
      "Total PID Loss 2.800699 lambda= 0.75\n",
      "Total PID Loss 2.800674 lambda= 0.75\n",
      "Total PID Loss 2.800699 lambda= 0.75\n",
      "Total PID Loss 2.8007239999999998 lambda= 0.75\n",
      "Total PID Loss 2.800674 lambda= 0.75\n",
      "Total PID Loss 2.800649 lambda= 0.75\n",
      "Total PID Loss 2.8006990000000003 lambda= 0.75\n",
      "Total PID Loss 2.800749 lambda= 0.75\n",
      "Total PID Loss 2.800699 lambda= 0.75\n",
      "Total PID Loss 2.8007610000000005 lambda= 0.75\n",
      "Total PID Loss 2.8007239999999998 lambda= 0.75\n",
      "Total PID Loss 2.800649 lambda= 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 2.800649 lambda= 0.75\n",
      "Total PID Loss 2.800699 lambda= 0.75\n",
      "Total PID Loss 2.800699 lambda= 0.75\n",
      "Total PID Loss 2.8184365000000002 lambda= 0.875\n",
      "Total PID Loss 3.0938389999999982 lambda= 0.875\n",
      "Total PID Loss 2.818524 lambda= 0.875\n",
      "Total PID Loss 2.8430159999999995 lambda= 0.875\n",
      "Total PID Loss 2.818611 lambda= 0.875\n",
      "Total PID Loss 3.0959035 lambda= 0.875\n",
      "Total PID Loss 2.885200000000001 lambda= 0.875\n",
      "Total PID Loss 2.8973249999999995 lambda= 0.875\n",
      "Total PID Loss 2.8363765 lambda= 0.875\n",
      "Total PID Loss 2.8069434999999996 lambda= 0.875\n",
      "Total PID Loss 2.810044 lambda= 0.875\n",
      "Total PID Loss 2.826776 lambda= 0.875\n",
      "Total PID Loss 2.8162815 lambda= 0.875\n",
      "Total PID Loss 2.8084940000000005 lambda= 0.875\n",
      "Total PID Loss 2.8051435 lambda= 0.875\n",
      "Total PID Loss 2.8025965 lambda= 0.875\n",
      "Total PID Loss 2.802594 lambda= 0.875\n",
      "Total PID Loss 2.8124835 lambda= 0.875\n",
      "Total PID Loss 2.8134714999999995 lambda= 0.875\n",
      "Total PID Loss 2.8048415 lambda= 0.875\n",
      "Total PID Loss 2.8116209999999997 lambda= 0.875\n",
      "Total PID Loss 2.8045660000000003 lambda= 0.875\n",
      "Total PID Loss 2.8032915000000003 lambda= 0.875\n",
      "Total PID Loss 2.804934 lambda= 0.875\n",
      "Total PID Loss 2.8029664999999997 lambda= 0.875\n",
      "Total PID Loss 2.8067389999999994 lambda= 0.875\n",
      "Total PID Loss 2.8028625000000003 lambda= 0.875\n",
      "Total PID Loss 2.8049910000000002 lambda= 0.875\n",
      "Total PID Loss 2.802561 lambda= 0.875\n",
      "Total PID Loss 2.8027060000000006 lambda= 0.875\n",
      "Total PID Loss 2.8029135000000003 lambda= 0.875\n",
      "Total PID Loss 2.8024915 lambda= 0.875\n",
      "Total PID Loss 2.803004 lambda= 0.875\n",
      "Total PID Loss 2.8024875 lambda= 0.875\n",
      "Total PID Loss 2.80265 lambda= 0.875\n",
      "Total PID Loss 2.802409 lambda= 0.875\n",
      "Total PID Loss 2.802656 lambda= 0.875\n",
      "Total PID Loss 2.8024109999999998 lambda= 0.875\n",
      "Total PID Loss 2.8028009999999997 lambda= 0.875\n",
      "Total PID Loss 2.8023965 lambda= 0.875\n",
      "Total PID Loss 2.802529 lambda= 0.875\n",
      "Total PID Loss 2.8024165 lambda= 0.875\n",
      "Total PID Loss 2.8025564999999997 lambda= 0.875\n",
      "Total PID Loss 2.8023884999999997 lambda= 0.875\n",
      "Total PID Loss 2.8024285000000004 lambda= 0.875\n",
      "Total PID Loss 2.802329 lambda= 0.875\n",
      "Total PID Loss 2.8024664999999995 lambda= 0.875\n",
      "Total PID Loss 2.8023410000000006 lambda= 0.875\n",
      "Total PID Loss 2.8024665000000004 lambda= 0.875\n",
      "Total PID Loss 2.8024215 lambda= 0.875\n",
      "Total PID Loss 2.802334 lambda= 0.875\n",
      "Total PID Loss 2.802401 lambda= 0.875\n",
      "Total PID Loss 2.802359 lambda= 0.875\n",
      "Total PID Loss 2.8024215 lambda= 0.875\n",
      "Total PID Loss 2.802354 lambda= 0.875\n",
      "Total PID Loss 2.802475 lambda= 0.875\n",
      "Total PID Loss 2.8024165000000005 lambda= 0.875\n",
      "Total PID Loss 2.8024215000000003 lambda= 0.875\n",
      "Total PID Loss 2.802379 lambda= 0.875\n",
      "Total PID Loss 2.8023965000000004 lambda= 0.875\n",
      "Total PID Loss 2.802454 lambda= 0.875\n",
      "Total PID Loss 2.8024035000000005 lambda= 0.875\n",
      "Total PID Loss 2.8024715000000002 lambda= 0.875\n",
      "Total PID Loss 2.8023965 lambda= 0.875\n",
      "Total PID Loss 2.802404 lambda= 0.875\n",
      "Total PID Loss 2.8023965000000004 lambda= 0.875\n",
      "Total PID Loss 2.8023915 lambda= 0.875\n",
      "Total PID Loss 2.802404 lambda= 0.875\n",
      "Total PID Loss 2.8024215000000003 lambda= 0.875\n",
      "Total PID Loss 2.8023540000000002 lambda= 0.875\n",
      "Total PID Loss 2.802404 lambda= 0.875\n",
      "Total PID Loss 2.8024590000000003 lambda= 0.875\n",
      "Total PID Loss 2.8024090000000004 lambda= 0.875\n",
      "Total PID Loss 2.8023415000000003 lambda= 0.875\n",
      "Total PID Loss 2.802354 lambda= 0.875\n",
      "Total PID Loss 2.8023290000000003 lambda= 0.875\n",
      "Total PID Loss 2.8024165 lambda= 0.875\n",
      "Total PID Loss 2.8023665 lambda= 0.875\n",
      "Total PID Loss 2.8023664999999998 lambda= 0.875\n",
      "Total PID Loss 2.8023789999999997 lambda= 0.875\n",
      "Total PID Loss 2.8023415 lambda= 0.875\n",
      "Total PID Loss 2.8023415000000003 lambda= 0.875\n",
      "Total PID Loss 2.802354 lambda= 0.875\n",
      "Total PID Loss 2.802354 lambda= 0.875\n",
      "Total PID Loss 2.802354 lambda= 0.875\n",
      "Total PID Loss 2.8023664999999998 lambda= 0.875\n",
      "Total PID Loss 2.802354 lambda= 0.875\n",
      "Total PID Loss 2.802329 lambda= 0.875\n",
      "Total PID Loss 2.8023789999999997 lambda= 0.875\n",
      "Total PID Loss 2.8023415 lambda= 0.875\n",
      "Total PID Loss 2.8023415 lambda= 0.875\n",
      "Total PID Loss 2.790004 lambda= 1.0\n",
      "Total PID Loss 3.1081999999999987 lambda= 1.0\n",
      "Total PID Loss 2.790104 lambda= 1.0\n",
      "Total PID Loss 2.811801 lambda= 1.0\n",
      "Total PID Loss 2.790004 lambda= 1.0\n",
      "Total PID Loss 3.135904000000001 lambda= 1.0\n",
      "Total PID Loss 2.8633959999999994 lambda= 1.0\n",
      "Total PID Loss 2.8895 lambda= 1.0\n",
      "Total PID Loss 2.807964 lambda= 1.0\n",
      "Total PID Loss 2.7870089999999994 lambda= 1.0\n",
      "Total PID Loss 2.8149039999999994 lambda= 1.0\n",
      "Total PID Loss 2.7931 lambda= 1.0\n",
      "Total PID Loss 2.786289 lambda= 1.0\n",
      "Total PID Loss 2.781456 lambda= 1.0\n",
      "Total PID Loss 2.780325 lambda= 1.0\n",
      "Total PID Loss 2.780689 lambda= 1.0\n",
      "Total PID Loss 2.7888890000000006 lambda= 1.0\n",
      "Total PID Loss 2.781584 lambda= 1.0\n",
      "Total PID Loss 2.779876 lambda= 1.0\n",
      "Total PID Loss 2.788644 lambda= 1.0\n",
      "Total PID Loss 2.7947000000000006 lambda= 1.0\n",
      "Total PID Loss 2.780309 lambda= 1.0\n",
      "Total PID Loss 2.782625 lambda= 1.0\n",
      "Total PID Loss 2.779301 lambda= 1.0\n",
      "Total PID Loss 2.781376 lambda= 1.0\n",
      "Total PID Loss 2.7791360000000003 lambda= 1.0\n",
      "Total PID Loss 2.779661 lambda= 1.0\n",
      "Total PID Loss 2.7774249999999996 lambda= 1.0\n",
      "Total PID Loss 2.778281 lambda= 1.0\n",
      "Total PID Loss 2.781325 lambda= 1.0\n",
      "Total PID Loss 2.7782999999999998 lambda= 1.0\n",
      "Total PID Loss 2.7819 lambda= 1.0\n",
      "Total PID Loss 2.778125 lambda= 1.0\n",
      "Total PID Loss 2.778596 lambda= 1.0\n",
      "Total PID Loss 2.779896 lambda= 1.0\n",
      "Total PID Loss 2.7780760000000004 lambda= 1.0\n",
      "Total PID Loss 2.7784809999999998 lambda= 1.0\n",
      "Total PID Loss 2.777929 lambda= 1.0\n",
      "Total PID Loss 2.778281 lambda= 1.0\n",
      "Total PID Loss 2.7777999999999996 lambda= 1.0\n",
      "Total PID Loss 2.778701 lambda= 1.0\n",
      "Total PID Loss 2.777856 lambda= 1.0\n",
      "Total PID Loss 2.777576 lambda= 1.0\n",
      "Total PID Loss 2.777484 lambda= 1.0\n",
      "Total PID Loss 2.7778690000000004 lambda= 1.0\n",
      "Total PID Loss 2.777641 lambda= 1.0\n",
      "Total PID Loss 2.777256 lambda= 1.0\n",
      "Total PID Loss 2.7773 lambda= 1.0\n",
      "Total PID Loss 2.7774249999999996 lambda= 1.0\n",
      "Total PID Loss 2.777224 lambda= 1.0\n",
      "Total PID Loss 2.7773250000000003 lambda= 1.0\n",
      "Total PID Loss 2.777341 lambda= 1.0\n",
      "Total PID Loss 2.777256 lambda= 1.0\n",
      "Total PID Loss 2.777321 lambda= 1.0\n",
      "Total PID Loss 2.7773 lambda= 1.0\n",
      "Total PID Loss 2.7774 lambda= 1.0\n",
      "Total PID Loss 2.7772689999999995 lambda= 1.0\n",
      "Total PID Loss 2.777384 lambda= 1.0\n",
      "Total PID Loss 2.7772689999999995 lambda= 1.0\n",
      "Total PID Loss 2.777261 lambda= 1.0\n",
      "Total PID Loss 2.777384 lambda= 1.0\n",
      "Total PID Loss 2.7772250000000005 lambda= 1.0\n",
      "Total PID Loss 2.777296 lambda= 1.0\n",
      "Total PID Loss 2.7773239999999997 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.7773610000000004 lambda= 1.0\n",
      "Total PID Loss 2.777256 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.7773239999999997 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777256 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.7773239999999997 lambda= 1.0\n",
      "Total PID Loss 2.777289 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n",
      "Total PID Loss 2.777189 lambda= 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m35results = createFrontier(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
